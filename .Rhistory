gender, Race, Education, state))
#salaries = subset(salaries, salaries$totalyearlycompensation < 1000000) #testing out removing salaries over 1mil (6 records)
#Model that has 'totalyearlycompensation' as the response variable and all remaining variables serve as the predictors
salaries_model = lm(totalyearlycompensation ~ ., data = salaries)
#Backward AIC
salaries_model_back_aic = step(salaries_model,
direction = "backward", trace = 0)
#Backward BIC
salaries_model_back_bic = step(salaries_model, direction = "backward",
k = log(nrow(salaries)), trace = 0)
anova(salaries_model_back_bic, salaries_model_back_aic)
#Check for collinearity
car::vif(salaries_model_back_aic) #Nothing too bad
#Transform log response to improve linearity
aic_model_log = lm(log(totalyearlycompensation) ~ company + yearsofexperience + title + level + gender + Race + Education, data = salaries)
#Add interactions to predictors to improve normality, linearity and constant variance
aic_model_trans = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + level + gender + Race + Education, data = salaries)
anova(aic_model_log, aic_model_trans)
#Remove influential data from the model
aic_model_final = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + level + gender + Race + Education, data = salaries, subset = cooks.distance(aic_model_trans) < 4 / length(cooks.distance(aic_model_trans)))
#Importing libraries
library(car)
library(lmtest)
library(boot)
library(caret)
#Run diagnostics
summary(aic_model_final)$adj
#get_loocv_rmse(aic_model_final)
shapiro.test(resid(aic_model_final))
bptest(aic_model_final)
#Plot diagnostics
par(mfrow = c(1, 2))
# Residuals vs Fitted values plot
plot(fitted(aic_model_fix), resid(aic_model_final), col = "grey", pch = 20,
xlab = "Fitted", ylab = "Residuals", main = "Fitted versus Residuals")
View(salaries)
options(digits = 4)
#Loading dataset and importing libraries
library(readr)
library(stringr)
salaries = read_csv("Levels-Fyi-Salary-Data-Cleaned-US.csv")
View(salaries)
options(digits = 4)
race = c("White", "Black", "Hispanic", "Asian", "Two Or More")
amamzon_salaries = rep(0, length(unique(salaries$Race)))
google_salaries = rep(0, length(unique(salaries$Race)))
for(i in 1:length(unique(salaries$Race))) {
sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
amamzon_salaries[i] = sal1
google_salaries[i] = sal2
}
options(digits = 4)
#Loading dataset and importing libraries
library(readr)
library(stringr)
salaries = read_csv("Levels-Fyi-Salary-Data-Cleaned-US.csv")
#Is this necessary?
#head(salaries)
#Remove NA records
salaries = na.omit(salaries)
#Changing some predictors to factors
salaries$company = as.factor(salaries$company)
salaries$level = as.factor(salaries$level)
salaries$title = as.factor(salaries$title)
salaries$location = as.factor(salaries$location)
salaries$gender = as.factor(salaries$gender)
salaries$Race = as.factor(salaries$Race)
salaries$Education = as.factor(salaries$Education)
#Variable Selection: Removed variables that contain redundant information or lack of information
salaries = subset(salaries, select = c(company, level, title,
totalyearlycompensation, location,
yearsofexperience, yearsatcompany, tag,
gender, Race, Education))
#Model w/ 'totalyearlycompensation' as the response variable and all remaining variables as the predictors
salaries_model = lm(totalyearlycompensation ~ ., data = salaries)
#Backward AIC
salaries_model_back_aic = step(salaries_model,
direction = "backward", trace = 0)
#Backward BIC
salaries_model_back_bic = step(salaries_model, direction = "backward",
k = log(nrow(salaries)), trace = 0)
#Performing anova test on the AIC and BIC models
anova(salaries_model_back_bic, salaries_model_back_aic)
#Checking the collinearity of the AIC model
car::vif(salaries_model_back_aic) #Nothing too bad
#Performing log response transformation to improve linearity
aic_model_log = lm(log(totalyearlycompensation) ~ company + yearsofexperience + title + level + gender + Race + Education, data = salaries)
#Add interactions to predictors to improve normality, linearity and constant variance
aic_model_trans = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + level + gender + Race + Education, data = salaries)
anova(aic_model_log, aic_model_trans)
#Removing influential data points from the model
aic_model_final = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + level + gender + Race + Education, data = salaries, subset = cooks.distance(aic_model_trans) < 4 / length(cooks.distance(aic_model_trans)))
#Importing libraries
library(car)
library(lmtest)
library(boot)
library(caret)
library(knitr)
#LOOCV RMSE Function - ...
get_loocv_rmse = function(model){
sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
#Diagnostics.. not sure if we should still include it now that its results are now in a table
#summary(aic_model_final)$adj
#get_loocv_rmse(aic_model_final)
#shapiro.test(resid(aic_model_final))$p.value
#test = bptest(aic_model_final)$p.value
#Diagnostics Table
row_names = c("Adjusted R", "LOOCV-RMSE", "Shapiro Test", "BP Test")
column_names = c(" ", "Model")
diagnostics = c(summary(aic_model_final)$adj,get_loocv_rmse(aic_model_final),
(shapiro.test(resid(aic_model_final))$p.value),
bptest(aic_model_final)$p.value)
df_results = data.frame(row_names, diagnostics)
kable(df_results, "simple", col.names = column_names)
#Importing library
library(caret)
#Split the data 70-30 train and test set
#trn_idx = sample(1:nrow(salaries), 1608)
set.seed(22)
trn_idx = createDataPartition(salaries$level, p = 0.7, list = F)
trn = salaries[trn_idx, ]
tst = salaries[-trn_idx, ]
#Calculating average percent error
actual_salary = tst$totalyearlycompensation
pred_salary = exp(predict(aic_model_final, tst))
max_salary = ifelse(max(actual_salary) > max(pred_salary), max(actual_salary), max(pred_salary))
percent_error = mean((abs(pred_salary - actual_salary) / pred_salary)) * 100
#Simulation Set-Up
num_sims = 1000
rmse_trn = rep(0, num_sims)
rmse_tst = rep(0, num_sims)
#RMSE Function - ...
rmse = function(y, y_hat){
sqrt(sum((y - y_hat) ^ 2) / length(y))
}
for(i in 1:num_sims){
sim_fit = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + level + gender + Race + Education, data = trn)
rmse_trn[i] = rmse(trn$totalyearlycompensation, exp(predict(sim_fit, trn)))
rmse_tst[i] = rmse(tst$totalyearlycompensation, exp(predict(sim_fit, tst)))
}
#Think we should comment this out and call this out in the results section
mean(rmse_trn)
mean(rmse_tst)
#Predict salaries
#salary_1 = data.frame(company = "Amazon", level = "L4", title = "Software Engineer", #yearsofexperience = 0, gender = "Female", Race = "Asian", Education = "Master's Degree") #150000
#salary_2 = data.frame(company = "Amazon", level = "L4", title = "Software Engineer", #yearsofexperience = 2, gender = "Male", Race = "Hispanic", Education = "Bachelor's Degree") #152000
#salary_3 = data.frame(company = "Google", level = "L5", title = "Software Engineer", #yearsofexperience = 9, gender = "Male", Race = "Asian", Education = "PhD") #396000
#exp(predict(aic_model_final, newdata = salary_1))
#exp(predict(aic_model_final, newdata = salary_2))
#exp(predict(aic_model_final, newdata = salary_3))
par(mfrow = c(1,3))
# Q-Q plot of initial model without log response transformation
qqnorm(resid(salaries_model_back_aic), main = "Normal Q-Q Plot Before Log Response", col = "darkgrey")
qqline(resid(salaries_model_back_aic), col = "dodgerblue", lwd = 2)
# Q-Q plot after log response transformation
qqnorm(resid(aic_model_log), main = "Normal Q-Q Plot After Log Response", col = "darkgrey")
qqline(resid(aic_model_log), col = "dodgerblue", lwd = 2)
# Q-Q plot after log response transformation
qqnorm(resid(aic_model_final), main = "Normal Q-Q Plot After All Transformations", col = "darkgrey")
qqline(resid(aic_model_final), col = "dodgerblue", lwd = 2)
par(mfrow = c(1,2))
#Residuals vs Fitted plot of initial model before transformation
plot(fitted(salaries_model_back_aic), resid(salaries_model_back_aic), col = "grey", pch = 20,
xlab = "Fitted", ylab = "Residuals", main = "Fitted versus Residuals Before Transformations")
abline(h = 0, col = "darkorange", lwd = 2)
#Residuals vs Fitted plot of final model after transformations
plot(fitted(aic_model_final), resid(aic_model_final), col = "grey", pch = 20,
xlab = "Fitted", ylab = "Residuals", main = "Fitted versus Residuals After Transformations")
abline(h = 0, col = "darkorange", lwd = 2)
#Insert table with other diagnostics, r.squared etc.
plot(pred_salary, actual_salary,
col = "darkgrey",
xlab = "Predicted Salaries Prices",
ylab = "Actual Salaries",
main = "Predicted vs. Actual Salaries",
xlim = c(0, max_salary),
ylim = c(0, max_salary)
)
abline(0, 1, col = "dodgerblue")
race = c("White", "Black", "Hispanic", "Asian", "Two Or More")
amamzon_salaries = rep(0, length(unique(salaries$Race)))
google_salaries = rep(0, length(unique(salaries$Race)))
for(i in 1:length(unique(salaries$Race))) {
sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
amamzon_salaries[i] = sal1
google_salaries[i] = sal2
}
#Plot
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(amamzon_salaries)),
main = "Amazon: L1 Salary Based on Race", ylab = "Total Compensation")
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(google_salaries)),
main = "Google: L1 Salary Based on Race", ylab = "Total Compensation")
#Will be used later for the discussion on why google entry level is so high
#exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
#exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
#HERE FOR NOW BUT WILL BE CLEANED UP
salaries = read_csv("Levels-Fyi-Salary-Data-Cleaned-US.csv")
#Remove NA records
salaries = na.omit(salaries)
#Create new column 'State' which converts location to just the state abbreviation
salaries$state = str_sub(salaries$location,-2,-1)
#Changing some predictors to factors
salaries$company = as.factor(salaries$company)
salaries$level = as.factor(salaries$level)
salaries$title = as.factor(salaries$title)
salaries$location = as.factor(salaries$location)
salaries$state = as.factor(salaries$state)
salaries$gender = as.factor(salaries$gender)
salaries$Race = as.factor(salaries$Race)
salaries$Education = as.factor(salaries$Education)
#Variable Selection: Removed variables that contain redundant information or lack of information
salaries = subset(salaries, select = c(company, level, title,
totalyearlycompensation,
yearsofexperience, yearsatcompany, tag,
gender, Race, state, Education))
salaries_model = lm(totalyearlycompensation ~ ., data = salaries)
#Didnt use p but n was used for model BIC models
#p = length(coef(salaries_model))
n = length(resid(salaries_model))
#Backward AIC
salaries_model_back_aic = step(salaries_model,
direction = "backward", trace = 0)
#Backward BIC
salaries_model_back_bic = step(salaries_model, direction = "backward",
k = log(nrow(salaries)), trace = 0)
salaries_model_start = lm(totalyearlycompensation ~ 1, data = salaries)
#Forward AIC
salaries_model_forw_aic = step(salaries_model_start,
scope = totalyearlycompensation ~ company + level +
title + yearsofexperience + yearsatcompany + tag +
gender + Race + Education + state,
direction = "forward", trace = 0)
#Forward BIC
salaries_model_forw_bic = step(salaries_model_start,
scope = totalyearlycompensation ~ company + level +
title + yearsofexperience + yearsatcompany + tag +
gender + Race + Education + state,
direction = "forward", k = log(nrow(salaries)), trace = 0)
#Stepwise AIC
salaries_model_both_aic = step(salaries_model_start,
scope = totalyearlycompensation ~ company + level +
title + yearsofexperience + yearsatcompany + tag +
gender + Race + Education + state,
direction = "both", trace = 0)
#Stepwise BIC
salaries_model_both_bic = step(salaries_model_start,
scope = totalyearlycompensation ~ company + level +
title + yearsofexperience + yearsatcompany + tag +
gender + Race + Education + state,
direction = "both", k = log(nrow(salaries)), trace = 0)
library(lmtest)
salaries_model_add = lm(log(totalyearlycompensation) ~ (yearsatcompany + company + title + state + level) ^ 2, data = salaries)
salaries_model_fix = lm(log(totalyearlycompensation) ~ (yearsatcompany + company + title + state + level) ^ 2, data = salaries, subset = cooks.distance(salaries_model_add) < 4 / length(cooks.distance(salaries_model_add)))
hist(resid(salaries_model_fix))
#salaries_model_int = lm(totalyearlycompensation ~ level * title * yearsofexperience * yearsatcompany, data = salaries)
#anova(salaries_model_add, salaries_model_int)
#summary(salaries_model_int)
#salaries_model_three_int = lm(totalyearlycompensation ~ company * level * yearsofexperience, data = salaries)
qqnorm(resid(salaries_model_fix))
qqline(resid(salaries_model_fix))
plot(fitted(salaries_model_fix), resid(salaries_model_fix))
abline(h=0)
shapiro.test(resid(salaries_model_fix))
bptest(salaries_model_fix)
#anova(salaries_model_add, salaries_model_two_int)
#anova(salaries_model_two_int, salaries_model_three_int)
library(car)
library(lmtest)
get_loocv_rmse = function(model){
sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
#start_model = lm(log(totalyearlycompensation) ~ . ^ 2, data = salaries)
#aic_model = step(start_model, direction = "backward", trace = 0)
#Check for collinearity
car::vif(salaries_model_both_aic) #Nothing too bad, perhaps level is high
#Transform log response and add interactions to predictors to improve normality, linearity, constant variance, adjusted R-squared, and loocv-RMSE
aic_model_trans_2 = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + level + gender + Race + Education, data = salaries)
aic_model_trans = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + gender + Race + Education + level, data = salaries)
anova(aic_model_trans, aic_model_trans_2)
#Remove influential data from the model
aic_model_fix = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + gender + Race + Education + level, data = salaries, subset = cooks.distance(aic_model_trans) < 4 / length(cooks.distance(aic_model_trans)))
#Run diagnostics
summary(aic_model_fix)$adj
get_loocv_rmse(aic_model_fix)
shapiro.test(resid(aic_model_fix))
bptest(aic_model_fix)
#Plot diagnostics
par(mfrow = c(1, 2))
# Residuals vs Fitted values plot
plot(fitted(aic_model_fix), resid(aic_model_fix), col = "grey", pch = 20,
xlab = "Fitted", ylab = "Residuals", main = "Fitted versus Residuals")
abline(h = 0, col = "darkorange", lwd = 2)
# Q-Q plot
qqnorm(resid(aic_model_fix), main = "Normal Q-Q Plot", col = "darkgrey")
qqline(resid(aic_model_fix), col = "dodgerblue", lwd = 2)
race = c("White", "Black", "Hispanic", "Asian", "Two Or More")
amamzon_salaries = rep(0, length(unique(salaries$Race)))
google_salaries = rep(0, length(unique(salaries$Race)))
for(i in 1:length(unique(salaries$Race))) {
sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
amamzon_salaries[i] = sal1
google_salaries[i] = sal2
}
#Plot
par(mfrow = c(1,2))
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(amamzon_salaries)),
main = "Amazon: L1 Salary Based on Race", ylab = "Total Compensation")
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(google_salaries)),
main = "Google: L1 Salary Based on Race", ylab = "Total Compensation")
#Will be used later for the discussion on why google entry level is so high
#exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
#exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
race = c("White", "Black", "Hispanic", "Asian", "Two Or More")
amamzon_salaries = rep(0, length(unique(salaries$Race)))
google_salaries = rep(0, length(unique(salaries$Race)))
for(i in 1:length(unique(salaries$Race))) {
sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
amamzon_salaries[i] = sal1
google_salaries[i] = sal2
}
#Plot
par(mfrow = c(1,2))
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(amamzon_salaries)),
main = "Amazon: L1 Salary Based on Race", ylab = "Total Compensation")
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(google_salaries)),
main = "Google: L1 Salary Based on Race", ylab = "Total Compensation")
#Will be used later for the discussion on why google entry level is so high
#exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
#exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
race = c("White", "Black", "Hispanic", "Asian", "Two Or More")
amamzon_salaries = rep(0, length(unique(salaries$Race)))
google_salaries = rep(0, length(unique(salaries$Race)))
for(i in 1:length(unique(salaries$Race))) {
sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
amamzon_salaries[i] = sal1
google_salaries[i] = sal2
}
#Plot
par(mfrow = c(1,2))
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(amamzon_salaries)),
main = "Amazon: L1 Salary Based on Race", ylab = "Total Compensation")
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(google_salaries)),
main = "Google: L1 Salary Based on Race", ylab = "Total Compensation")
#Will be used later for the discussion on why google entry level is so high
#exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
#exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
race = c("White", "Black", "Hispanic", "Asian", "Two Or More")
amamzon_salaries = rep(0, length(unique(salaries$Race)))
google_salaries = rep(0, length(unique(salaries$Race)))
for(i in 1:length(unique(salaries$Race))) {
sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
amamzon_salaries[i] = sal1
google_salaries[i] = sal2
}
#Plot
par(mfrow = c(1,2))
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(amamzon_salaries)),
main = "Amazon: L1 Salary Based on Race", ylab = "Total Compensation")
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(google_salaries)),
main = "Google: L1 Salary Based on Race", ylab = "Total Compensation")
#Will be used later for the discussion on why google entry level is so high
#exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
#exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
race = c("White", "Black", "Hispanic", "Asian", "Two Or More")
amamzon_salaries = rep(0, length(unique(salaries$Race)))
google_salaries = rep(0, length(unique(salaries$Race)))
for(i in 1:length(unique(salaries$Race))) {
sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
amamzon_salaries[i] = sal1
google_salaries[i] = sal2
}
#Plot
par(mfrow = c(1,2))
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(amamzon_salaries)),
main = "Amazon: L1 Salary Based on Race", ylab = "Total Compensation")
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(google_salaries)),
main = "Google: L1 Salary Based on Race", ylab = "Total Compensation")
#Will be used later for the discussion on why google entry level is so high
#exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
#exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
race = c("White", "Black", "Hispanic", "Asian", "Two Or More")
amamzon_salaries = rep(0, length(unique(salaries$Race)))
google_salaries = rep(0, length(unique(salaries$Race)))
for(i in 1:length(unique(salaries$Race))) {
sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
amamzon_salaries[i] = sal1
google_salaries[i] = sal2
}
#Plot
par(mfrow = c(1,2))
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(amamzon_salaries)),
main = "Amazon: L1 Salary Based on Race", ylab = "Total Compensation")
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(google_salaries)),
main = "Google: L1 Salary Based on Race", ylab = "Total Compensation")
#Will be used later for the discussion on why google entry level is so high
#exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
#exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
race = c("White", "Black", "Hispanic", "Asian", "Two Or More")
amamzon_salaries = rep(0, length(unique(salaries$Race)))
google_salaries = rep(0, length(unique(salaries$Race)))
for(i in 1:length(unique(salaries$Race))) {
sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
amamzon_salaries[i] = sal1
google_salaries[i] = sal2
}
#Plot
par(mfrow = c(1,2))
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(amamzon_salaries)),
main = "AMZN: L1 Salary Based on Race", ylab = "Total Compensation")
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(google_salaries)),
main = "GOOG: L1 Salary Based on Race", ylab = "Total Compensation")
#Will be used later for the discussion on why google entry level is so high
#exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
#exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
race = c("White", "Black", "Hispanic", "Asian", "Two Or More")
amamzon_salaries = rep(0, length(unique(salaries$Race)))
google_salaries = rep(0, length(unique(salaries$Race)))
for(i in 1:length(unique(salaries$Race))) {
sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
amamzon_salaries[i] = sal1
google_salaries[i] = sal2
}
#Plot
par(mfrow = c(1,2))
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(amamzon_salaries)),
main = "AMZN: L1 Salary Based on Race", ylab = "Total Compensation")
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(google_salaries)),
main = "GOOG: L1 Salary Based on Race", ylab = "Total Compensation")
#Will be used later for the discussion on why google entry level is so high
#exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
#exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
race = c("White", "Black", "Hispanic", "Asian", "Two Or More")
amamzon_salaries = rep(0, length(unique(salaries$Race)))
google_salaries = rep(0, length(unique(salaries$Race)))
for(i in 1:length(unique(salaries$Race))) {
sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
amamzon_salaries[i] = sal1
google_salaries[i] = sal2
}
#Plot
par(mfrow = c(1,2))
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(amamzon_salaries)),
main = "AMZN: L1 Salary Based on Race", ylab = "Total Compensation",
ylab(scales::dollar))
race = c("White", "Black", "Hispanic", "Asian", "Two Or More")
amamzon_salaries = rep(0, length(unique(salaries$Race)))
google_salaries = rep(0, length(unique(salaries$Race)))
for(i in 1:length(unique(salaries$Race))) {
sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
amamzon_salaries[i] = sal1
google_salaries[i] = sal2
}
#Plot
par(mfrow = c(1,2))
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(amamzon_salaries)),
main = "AMZN: L1 Salary Based on Race", ylab = "Total Compensation")
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(google_salaries)),
main = "GOOG: L1 Salary Based on Race", ylab = "Total Compensation")
#Will be used later for the discussion on why google entry level is so high
#exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
#exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
#Initializing variables for predicting a persons salary based upon their race
race = c("White", "Black", "Hispanic", "Asian", "Two Or More")
amamzon_salaries = rep(0, length(unique(salaries$Race)))
google_salaries = rep(0, length(unique(salaries$Race)))
for(i in 1:length(unique(salaries$Race))) {
sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
amamzon_salaries[i] = sal1
google_salaries[i] = sal2
}
#Plot
par(mfrow = c(1,2))
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(amamzon_salaries)),
main = "AMZN: L1 Salary Based on Race", ylab = "Total Compensation")
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(google_salaries)),
main = "GOOG: L1 Salary Based on Race", ylab = "Total Compensation")
#Will be used later for the discussion on why google entry level is so high
#exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
#exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
#Initializing variables for predicting a persons salary based upon their race
race = c("White", "Black", "Hispanic", "Asian", "Two Or More")
amamzon_salaries = rep(0, length(unique(salaries$Race)))
google_salaries = rep(0, length(unique(salaries$Race)))
for(i in 1:length(unique(salaries$Race))) {
sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
amamzon_salaries[i] = sal1
google_salaries[i] = sal2
}
#Plot
par(mfrow = c(1,2))
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(amamzon_salaries)),
main = "AMZN: L1 Salary Based on Race", ylab = "Total Compensation")
barplot(google_salaries, names.arg = race, col=rainbow(length(google_salaries)),
main = "GOOG: L1 Salary Based on Race", ylab = "Total Compensation")
#Will be used later for the discussion on why google entry level is so high
#exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
#exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
