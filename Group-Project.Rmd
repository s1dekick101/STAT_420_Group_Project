---
title: "Data Analysis of Tech. Salaries at Amazon and Google"
author: "The Statisticians"
date: "`r Sys.Date()`"
output:
  html_document: 
    theme: readable
    toc: yes
urlcolor: cyan
---

### <u>Introduction</u>

As data science students, we're intrigued by the compensation structures within leading tech companies like Amazon and Google. To delve into this interest, we're undertaking a project to analyze a dataset of 12,647 salary records from these companies, with an aim to construct a predictive model for annual total compensation.

This dataset, `Levels-Fyi-Salary-Data-Cleaned-US.csv`, provides a unique and in-depth perspective into the salary structures of numerous top-tier companies. The dataset encompasses 28 variables, covering a variety of aspects such as company, level, title, location, years of experience, years at the company, and various demographic factors including gender and education level. Of particular interest to us is the `totalyearlycompensation` variable, which will serve as the response variable in our analysis.

Our interest in this dataset is driven by our curiosity about the factors that influence annual compensation in top companies. We aim to identify the key variables and their interactions that significantly impact salary levels. This would provide insights that could be invaluable to a variety of stakeholders, from job seekers and employees to human resource professionals and policymakers.

The primary goal of creating a model with this data is to predict the `totalyearlycompensation` based on a set of predictor variables. This model will help us understand how different variables, including categorical ones like `level` and numeric ones such as `yearsofexperience` and `yearsatcompany`, contribute to the total yearly compensation of an employee. Through this process, we also hope to identify potential trends, anomalies, or points of interest that could provide further avenues for exploration and analysis.

***

### <u>Methods</u>

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(digits = 4)
```


#### Description of the original data file
- `timestamp`: Timestamp of data entry
- `company`: The company the employee works for, either Amazon or Google
- `level`: The rank of the employee, ranging from L1 through L10
- `title`: The job title of the employee
- `location`: The city, state that the employee resides in
- `totalyearlycompensation`: The total yearly compensation of the employee
- `yearsofexperience`: The total years of working experience of the employee
- `yearsatcompany`: The years at the company of the employee
- `tag`: A tag for additional information
- `basesalary`: Employee's annual base salary
- `stockgrantvalue`: Employee's annual stock grant value
- `bonus`: Employee's annual bonus
- `otherdetails`: Other details
- `cityid`: City id
- `dmaid`: Dma id
- `rowNumber`: Row number
- `Masters_Degree`: A dummy variable indicating employee's level of education
- `Bachelors_Degree`: A dummy variable indicating employee's level of education
- `Doctorate_Degree`: A dummy variable indicating employee's level of education
- `Highschool`: A dummy variable indicating employee's level of education
- `Some_College`: A dummy variable indicating employee's level of education
- `Race_Asian`: A dummy variable indicating employee's race
- `Race_White`: A dummy variable indicating employee's race
- `Race_Two_Or_More`: A dummy variable indicating employee's race
- `Race_Black`: A dummy variable indicating employee's race
- `Race_Hispanic`: A dummy variable indicating employee's race
- `gender`: The gender of the employee
- `Race`: The race of the employee
- `Education`: The education level of the employee

#### Data Pre-Processing 

First, we had to clean and prepare our data to make it fit for analysis. We removed any records with missing values, and converted all categorical variables into factors. We chose to exclude certain columns from our final data set for these reasons: 

- The column was not a descriptive attribute of the employee (`timestamp`, `cityid`, `dmaid`) 
- The column was a dummy variable with the redundant data stored in another column (`Masters_Degree`, `Bachelors_Degree`, `Doctorate_Degree`, `Highschool`, `Some_College`, `Race_Asian`, `Race_White`, `Race_Two_Or_More`, `Race_Black`, `Race_Hispanic`)

Lastly, we excluded columns `basesalary`, `stockgrantvalue`, and `bonus` as we discovered that these fields were providing contradictory data. These three values are supposed to sum up to `totalyearlycompensation`; however, this was not the case the majority of the time. This is most likely due to faulty or missing user entry.

```{r message=FALSE, warning=FALSE}
#Loading dataset and importing libraries
library(readr)
library(stringr)
salaries = read_csv("Levels-Fyi-Salary-Data-Cleaned-US.csv")

#Is this necessary?
#head(salaries)

#Remove NA records
salaries = na.omit(salaries)

#Changing some predictors to factors
salaries$company = as.factor(salaries$company)
salaries$level = as.factor(salaries$level)
salaries$title = as.factor(salaries$title)
salaries$location = as.factor(salaries$location)
salaries$gender = as.factor(salaries$gender)
salaries$Race = as.factor(salaries$Race)
salaries$Education = as.factor(salaries$Education)

#Variable Selection: Removed variables that contain redundant information or lack of information 
salaries = subset(salaries, select = c(company, level, title,
                                       totalyearlycompensation, location,
                                       yearsofexperience, yearsatcompany, tag,
                                       gender, Race, Education))
```

#### Model Selection Proccess 

##### 1. Selection of Predictors Using AIC/BIC Methodology

```{r}
#Model w/ 'totalyearlycompensation' as the response variable and all remaining variables as the predictors
salaries_model = lm(totalyearlycompensation ~ ., data = salaries)

#Backward AIC
salaries_model_back_aic = step(salaries_model,
                               direction = "backward", trace = 0)

#Backward BIC
salaries_model_back_bic = step(salaries_model, direction = "backward",
                               k = log(nrow(salaries)), trace = 0)
```

-- Using the AIC searching method, we derive a model that uses 7 of the 10 given predictors

   Selected Predictors: **<u>`r all.vars(formula(salaries_model_back_aic)[-1])`</u>**
  
-- Using the BIC searching method, we derive a model that uses 4 of the 10 given predictors

   Selected Predictors: **<u>`r all.vars(formula(salaries_model_back_bic)[-1])`</u>**

Please see Appendix for forward and stepwise procedures.
  

```{r}
#Performing anova test on the AIC and BIC models 
anova(salaries_model_back_bic, salaries_model_back_aic)
```

Based upon the results of our test, we calculate a p-value of **`r anova(salaries_model_back_bic, salaries_model_back_aic)[2, "Pr(>F)"]`** meaning that we reject the BIC model and accept the larger AIC model (`salaries_model_back_aic`). 

```{r}
#Checking the collinearity of the AIC model 
car::vif(salaries_model_back_aic) #Nothing too bad
```
  
##### 2. Performing Model Transformations

```{r}
#Performing log response transformation to improve linearity
aic_model_log = lm(log(totalyearlycompensation) ~ company + yearsofexperience + title + level + gender + Race + Education, data = salaries)

#Add interactions to predictors to improve normality, linearity and constant variance
aic_model_trans = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + level + gender + Race + Education, data = salaries)

anova(aic_model_log, aic_model_trans)
```

Based upon the results of our anova test, we calculated a p-value of < **`r anova(aic_model_log, aic_model_trans)[2, "Pr(>F)"]`** meaning that we reject the log model (`aic_model_log`) and would prefer the full transformation model(`aic_model_trans`). 

```{r}
#Removing influential data points from the model
aic_model_final = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + level + gender + Race + Education, data = salaries, subset = cooks.distance(aic_model_trans) < 4 / length(cooks.distance(aic_model_trans)))
```

Cook's distance was employed to identify influential data points in the `aic_model_trans`. A threshold was set, typically at 4/`n`, where `n` is the number of observations. Observations with a Cook's distance larger than this threshold were considered influential and were removed.

##### 3. Run Diagnostics

```{r message=FALSE, warning=FALSE}
#Importing libraries
library(car)
library(lmtest)
library(boot)
library(caret)
library(knitr)

#LOOCV RMSE Function - ... 
get_loocv_rmse = function(model){
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

#Diagnostics.. not sure if we should still include it now that its results are now in a table 
#summary(aic_model_final)$adj 
#get_loocv_rmse(aic_model_final)
#shapiro.test(resid(aic_model_final))$p.value
#test = bptest(aic_model_final)$p.value

#Diagnostics Table 
row_names = c("Adjusted R", "LOOCV-RMSE", "Shapiro Test", "BP Test")
column_names = c(" ", "Model")
diagnostics = c(summary(aic_model_final)$adj,get_loocv_rmse(aic_model_final),
                (shapiro.test(resid(aic_model_final))$p.value),
                bptest(aic_model_final)$p.value)
df_results = data.frame(row_names, diagnostics)
kable(df_results, "simple", col.names = column_names)
```


##### 4. Testing model using test / train 

```{r, message = FALSE, warning = FALSE}
#Importing library 
library(caret)

#Split the data 70-30 train and test set
#trn_idx = sample(1:nrow(salaries), 1608)
set.seed(22)
trn_idx = createDataPartition(salaries$level, p = 0.7, list = F)
trn = salaries[trn_idx, ]
tst = salaries[-trn_idx, ]

#Calculating average percent error
actual_salary = tst$totalyearlycompensation
pred_salary = exp(predict(aic_model_final, tst))
max_salary = ifelse(max(actual_salary) > max(pred_salary), max(actual_salary), max(pred_salary))
percent_error = mean((abs(pred_salary - actual_salary) / pred_salary)) * 100
```

##### 5. Model simulation  

```{r, message = FALSE, warning = FALSE}

#Simulation Set-Up
num_sims = 1000
rmse_trn = rep(0, num_sims)
rmse_tst = rep(0, num_sims)

#RMSE Function - ... 
rmse = function(y, y_hat){
  sqrt(sum((y - y_hat) ^ 2) / length(y))
}

for(i in 1:num_sims){
  sim_fit = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + level + gender + Race + Education, data = trn)
  
  rmse_trn[i] = rmse(trn$totalyearlycompensation, exp(predict(sim_fit, trn)))
  rmse_tst[i] = rmse(tst$totalyearlycompensation, exp(predict(sim_fit, tst)))
}

#Think we should comment this out and call this out in the results section
mean(rmse_trn)
mean(rmse_tst)
```


##### 6. Model Predictions  

```{r, message = FALSE, warning = FALSE}

#Predict salaries
#salary_1 = data.frame(company = "Amazon", level = "L4", title = "Software Engineer", #yearsofexperience = 0, gender = "Female", Race = "Asian", Education = "Master's Degree") #150000

#salary_2 = data.frame(company = "Amazon", level = "L4", title = "Software Engineer", #yearsofexperience = 2, gender = "Male", Race = "Hispanic", Education = "Bachelor's Degree") #152000

#salary_3 = data.frame(company = "Google", level = "L5", title = "Software Engineer", #yearsofexperience = 9, gender = "Male", Race = "Asian", Education = "PhD") #396000

#exp(predict(aic_model_final, newdata = salary_1))
#exp(predict(aic_model_final, newdata = salary_2))
#exp(predict(aic_model_final, newdata = salary_3))
```
***

### <u>Results</u>

Based on our results, we expect our model to deliver a **`r 100 - percent_error`%** accuracy rating.

#### Diagnostics

##### Q-Q Plots

```{r, fig.dim = c(12, 10)}
par(mfrow = c(1,3))

# Q-Q plot of initial model without log response transformation
qqnorm(resid(salaries_model_back_aic), main = "Normal Q-Q Plot Before Log Response", col = "darkgrey")
qqline(resid(salaries_model_back_aic), col = "dodgerblue", lwd = 2)

# Q-Q plot after log response transformation
qqnorm(resid(aic_model_log), main = "Normal Q-Q Plot After Log Response", col = "darkgrey")
qqline(resid(aic_model_log), col = "dodgerblue", lwd = 2)

# Q-Q plot after all transformations
qqnorm(resid(aic_model_final), main = "Normal Q-Q Plot After All Transformations", col = "darkgrey")
qqline(resid(aic_model_final), col = "dodgerblue", lwd = 2)
```

##### Residuals vs. Fitted Plots
```{r, fig.dim = c(12, 10)}
par(mfrow = c(1,3))

#Residuals vs Fitted plot of initial model without log response transformation
plot(fitted(salaries_model_back_aic), resid(salaries_model_back_aic), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Resids Before Log Response")
abline(h = 0, col = "darkorange", lwd = 2)

#Residuals vs Fitted plot after log response transformation
plot(fitted(aic_model_log), resid(aic_model_log), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Resids After Log Response")
abline(h = 0, col = "darkorange", lwd = 2)

#Residuals vs Fitted plot after all transformations
plot(fitted(aic_model_final), resid(aic_model_final), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Resids After All Transformations")
abline(h = 0, col = "darkorange", lwd = 2)
```


```{r}
#Insert table with other diagnostics, r.squared etc. 
```

Percent Error - Fitted vs. Actual Plot
```{r}
plot(pred_salary, actual_salary,
     col = "darkgrey",
     xlab = "Predicted Salaries Prices",
     ylab = "Actual Salaries",
     main = "Predicted vs. Actual Salaries",
     xlim = c(0, max_salary),
     ylim = c(0, max_salary)
     )
abline(0, 1, col = "dodgerblue")
```


Predictions?
```{r}

```


Practical Application of Model 
```{r, fig.dim = c(12, 10)}

#Initializing variables for predicting a persons salary based upon their race
race = c("White", "Black", "Hispanic", "Asian", "Two Or More")
amamzon_salaries = rep(0, length(unique(salaries$Race)))
google_salaries = rep(0, length(unique(salaries$Race)))

for(i in 1:length(unique(salaries$Race))) {
  sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
  sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))

  amamzon_salaries[i] = sal1
  google_salaries[i] = sal2
}

#Plot
par(mfrow = c(1,2))
barplot(amamzon_salaries, names.arg = race, col=rainbow(length(amamzon_salaries)), 
        main = "AMZN: L1 Salary Based on Race", ylab = "Total Compensation")
barplot(google_salaries, names.arg = race, col=rainbow(length(google_salaries)), 
        main = "GOOG: L1 Salary Based on Race", ylab = "Total Compensation")

#Will be used later for the discussion on why google entry level is so high
#exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
#exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
```

***

### <u>Discussion</u>

#### Understanding the Final Model

Our final model, `aic_model_final`, includes interactions between company, years of experience, and title, along with other factors such as level, gender, race, and education. The model was carefully constructed through multiple steps including log transformation, interaction exploration, and removal of influential data points.

#### Key Findings

1. **Interactions**: The interactions between company, yearsofexperience, and title suggest that the relationship between these factors and total yearly compensation is not simply additive. This reflects the complexity of compensation structures in the real world, where various elements can synergistically affect the outcome.

2. **Transformations and Subset Selection**: Log transformation of the total yearly compensation helped to linearize the relationship with predictors. Additionally, the use of Cook's distance to exclude influential points contributed to model robustness.

3. **Significance of Factors**: The inclusion of categorical variables such as gender, race, and education may imply societal or industry-specific trends affecting salary. These factors should be interpreted with caution and in the context of broader research and understanding.

#### Utility of the Final Model

The final model, known as `aic_model_final`, represents an intricate understanding of how various factors like company, years of experience, title, level, gender, race, and education interact to influence total yearly compensation. This is not only a strategic tool for HR professionals but also a subject of great interest for data science students like us, and potentially a valuable resource for sociological studies.

The realization that factors such as gender, race, and education can significantly impact total yearly compensation even in tech companies brings additional depth to the model. It goes beyond mere corporate strategy, offering insights that can be applied in social science research to understand biases and inequalities in the workplace.

Individuals seeking jobs, organizations aiming to design more tailored and competitive compensation plans, and researchers examining societal trends can all benefit from this model. The nuanced understanding of how different variables interplay offers a unique lens into the underlying dynamics of the job market.

However, the model's utility is not without caveats. Its specific interactions and potential biases in data collection may limit its generalizability. The handling of sensitive areas such as gender and race requires thoughtful consideration, ensuring that insights align with ethical guidelines.

In conclusion, `aic_model_final` is a robust and multifaceted tool. Its applications are broad, ranging from individual and organizational decision-making to broader sociological analysis. It must be leveraged thoughtfully to realize its full potential and contribute to a more informed and equitable society.

#### Limitations and Areas for Improvement

***

### <u>Appendix</u> 


```{r warning=FALSE}
#HERE FOR NOW BUT WILL BE CLEANED UP
salaries = read_csv("Levels-Fyi-Salary-Data-Cleaned-US.csv")

#Remove NA records
salaries = na.omit(salaries)

#Create new column 'State' which converts location to just the state abbreviation
salaries$state = str_sub(salaries$location,-2,-1)

#Changing some predictors to factors
salaries$company = as.factor(salaries$company)
salaries$level = as.factor(salaries$level)
salaries$title = as.factor(salaries$title)
salaries$location = as.factor(salaries$location)
salaries$state = as.factor(salaries$state)
salaries$gender = as.factor(salaries$gender)
salaries$Race = as.factor(salaries$Race)
salaries$Education = as.factor(salaries$Education)

#Variable Selection: Removed variables that contain redundant information or lack of information 
salaries = subset(salaries, select = c(company, level, title,
                                       totalyearlycompensation,
                                       yearsofexperience, yearsatcompany, tag,
                                       gender, Race, state, Education))
```


Linear Model that includes all predictors
```{r}
salaries_model = lm(totalyearlycompensation ~ ., data = salaries)
```

AIC/BIC Models
```{r}
#Didnt use p but n was used for model BIC models  
#p = length(coef(salaries_model))
n = length(resid(salaries_model))

#Backward AIC
salaries_model_back_aic = step(salaries_model,
                               direction = "backward", trace = 0)

#Backward BIC
salaries_model_back_bic = step(salaries_model, direction = "backward",
                               k = log(nrow(salaries)), trace = 0)

salaries_model_start = lm(totalyearlycompensation ~ 1, data = salaries)

#Forward AIC
salaries_model_forw_aic = step(salaries_model_start, 
                               scope = totalyearlycompensation ~ company + level +
                               title + yearsofexperience + yearsatcompany + tag +
                               gender + Race + Education + state,
                               direction = "forward", trace = 0)

#Forward BIC
salaries_model_forw_bic = step(salaries_model_start, 
                               scope = totalyearlycompensation ~ company + level +
                               title + yearsofexperience + yearsatcompany + tag +
                               gender + Race + Education + state,
                               direction = "forward", k = log(nrow(salaries)), trace = 0)

#Stepwise AIC
salaries_model_both_aic = step(salaries_model_start, 
                               scope = totalyearlycompensation ~ company + level +
                               title + yearsofexperience + yearsatcompany + tag +
                               gender + Race + Education + state,
                               direction = "both", trace = 0)

#Stepwise BIC
salaries_model_both_bic = step(salaries_model_start, 
                               scope = totalyearlycompensation ~ company + level +
                               title + yearsofexperience + yearsatcompany + tag +
                               gender + Race + Education + state,
                               direction = "both", k = log(nrow(salaries)), trace = 0)
```


-- Using AIC searching methods we derive the same model that use 9 of the 10 given predictors

  AIC Selected Predictors: **<u>`r all.vars(formula(salaries_model_both_aic)[-1])`</u>**
  
-- Using BIC searching methods we derive the same model that use 4 of the 10 given predictors

  AIC Selected Predictors: **<u>`r all.vars(formula(salaries_model_both_bic)[-1])`</u>**


Model 2 
```{r}
library(lmtest)
salaries_model_add = lm(log(totalyearlycompensation) ~ (yearsatcompany + company + title + state + level) ^ 2, data = salaries)
 
salaries_model_fix = lm(log(totalyearlycompensation) ~ (yearsatcompany + company + title + state + level) ^ 2, data = salaries, subset = cooks.distance(salaries_model_add) < 4 / length(cooks.distance(salaries_model_add)))

hist(resid(salaries_model_fix))
 
#salaries_model_int = lm(totalyearlycompensation ~ level * title * yearsofexperience * yearsatcompany, data = salaries)

#anova(salaries_model_add, salaries_model_int)
#summary(salaries_model_int)

#salaries_model_three_int = lm(totalyearlycompensation ~ company * level * yearsofexperience, data = salaries)

qqnorm(resid(salaries_model_fix))
qqline(resid(salaries_model_fix))
plot(fitted(salaries_model_fix), resid(salaries_model_fix))
abline(h=0)
shapiro.test(resid(salaries_model_fix))
bptest(salaries_model_fix)
#anova(salaries_model_add, salaries_model_two_int)

#anova(salaries_model_two_int, salaries_model_three_int)

```


Model Selection
```{r}
library(car)
library(lmtest)

get_loocv_rmse = function(model){
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
#start_model = lm(log(totalyearlycompensation) ~ . ^ 2, data = salaries)
#aic_model = step(start_model, direction = "backward", trace = 0)
#Check for collinearity
car::vif(salaries_model_both_aic) #Nothing too bad, perhaps level is high

#Transform log response and add interactions to predictors to improve normality, linearity, constant variance, adjusted R-squared, and loocv-RMSE
aic_model_trans_2 = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + level + gender + Race + Education, data = salaries)

aic_model_trans = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + gender + Race + Education + level, data = salaries)

anova(aic_model_trans, aic_model_trans_2)

#Remove influential data from the model
aic_model_fix = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + gender + Race + Education + level, data = salaries, subset = cooks.distance(aic_model_trans) < 4 / length(cooks.distance(aic_model_trans)))

#Run diagnostics
summary(aic_model_fix)$adj 
get_loocv_rmse(aic_model_fix)
shapiro.test(resid(aic_model_fix))
bptest(aic_model_fix)

#Plot diagnostics
par(mfrow = c(1, 2))

# Residuals vs Fitted values plot
plot(fitted(aic_model_fix), resid(aic_model_fix), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted versus Residuals")
abline(h = 0, col = "darkorange", lwd = 2)

# Q-Q plot
qqnorm(resid(aic_model_fix), main = "Normal Q-Q Plot", col = "darkgrey")
qqline(resid(aic_model_fix), col = "dodgerblue", lwd = 2)
```

Putting this in the appendix for now
```{r}
#Create new column 'State' which converts location to just the state abbreviation
#salaries$state = str_sub(salaries$location,-2,-1)
```

By: Nicholas O. Brown, Ellie Jung, Angela Mei

***

