---
title: "Data Analysis of Tech. Salaries at Amazon and Google"
author: "The Statisticians"
date: "`r Sys.Date()`"
output:
  html_document: 
    theme: readable
    toc: yes
    toc_depth: 5
urlcolor: cyan
---

### <u>Introduction</u>

As data science students, we're intrigued by the compensation structures within leading tech companies like Amazon and Google. To delve into this interest, we're undertaking a project to analyze a dataset of 12,647 salary records from these two companies, with an aim to construct a predictive model for annual total compensation. This dataset was originally created on Kaggle, with data sourced from scraping levels.fyi.

This dataset, `Levels-Fyi-Salary-Data-Cleaned-US.csv`, provides a unique and in-depth perspective into the salary structures of numerous top-tier companies. The dataset encompasses 28 variables, covering a variety of aspects such as company, level, title, location, years of experience, years at the company, and various demographic factors including gender and education level. Of particular interest to us is the `totalyearlycompensation` variable, which will serve as the response variable in our analysis.

Our interest in this dataset is driven by our curiosity about the factors that influence annual compensation in top companies. We aim to identify the key variables and their interactions that significantly impact salary levels. This would provide insights that could be invaluable to a variety of stakeholders, from job seekers and employees to human resource professionals and policymakers.

The primary goal of creating a model with this data is to predict the `totalyearlycompensation` based on a set of predictor variables. This model will help us understand how different variables, including categorical ones like `level` and numeric ones such as `yearsofexperience` and `yearsatcompany`, contribute to the total yearly compensation of an employee. Through this process, we also hope to identify potential trends, anomalies, or points of interest that could provide further avenues for exploration and analysis.

***

### <u>Methods</u>

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(digits = 4)
```


#### Description of the original data file
- `timestamp`: Timestamp of data entry
- `company`: The company the employee works for, either Amazon or Google
- `level`: The rank of the employee, ranging from L1 through L10
- `title`: The job title of the employee
- `location`: The city, state that the employee resides in
- `totalyearlycompensation`: The total yearly compensation of the employee
- `yearsofexperience`: The total years of working experience of the employee
- `yearsatcompany`: The years at the company of the employee
- `tag`: A tag for additional information
- `basesalary`: Employee's annual base salary
- `stockgrantvalue`: Employee's annual stock grant value
- `bonus`: Employee's annual bonus
- `otherdetails`: Other details
- `cityid`: City id
- `dmaid`: Dma id
- `rowNumber`: Row number
- `Masters_Degree`: A dummy variable indicating employee's level of education
- `Bachelors_Degree`: A dummy variable indicating employee's level of education
- `Doctorate_Degree`: A dummy variable indicating employee's level of education
- `Highschool`: A dummy variable indicating employee's level of education
- `Some_College`: A dummy variable indicating employee's level of education
- `Race_Asian`: A dummy variable indicating employee's race
- `Race_White`: A dummy variable indicating employee's race
- `Race_Two_Or_More`: A dummy variable indicating employee's race
- `Race_Black`: A dummy variable indicating employee's race
- `Race_Hispanic`: A dummy variable indicating employee's race
- `gender`: The gender of the employee
- `Race`: The race of the employee
- `Education`: The education level of the employee

#### Data Pre-Processing 

First, we had to clean and prepare our data to make it fit for analysis. We removed any records with missing values, and converted all categorical variables into factors. We chose to exclude certain columns from our final dataset for these reasons: 

- The column was not a descriptive attribute of the employee (`timestamp`, `cityid`, `dmaid`, `rowNumber`) 
- The column was a dummy variable with redundant data also stored in another column (`Masters_Degree`, `Bachelors_Degree`, `Doctorate_Degree`, `Highschool`, `Some_College`, `Race_Asian`, `Race_White`, `Race_Two_Or_More`, `Race_Black`, `Race_Hispanic`, `otherdetails`)

Lastly, we excluded columns `basesalary`, `stockgrantvalue`, and `bonus` as we discovered that these fields were providing contradictory data. These three values are supposed to sum up to `totalyearlycompensation`; however, this was not the case the majority of the time. This is most likely due to faulty or missing user entry.

```{r message=FALSE, warning=FALSE}
#Loading dataset and importing libraries
library(readr)
library(stringr)
salaries = read_csv("Levels-Fyi-Salary-Data-Cleaned-US.csv")

#Remove NA records
salaries = na.omit(salaries)

#Changing some predictors to factors
salaries$company = as.factor(salaries$company)
salaries$level = as.factor(salaries$level)
salaries$title = as.factor(salaries$title)
salaries$location = as.factor(salaries$location)
salaries$gender = as.factor(salaries$gender)
salaries$Race = as.factor(salaries$Race)
salaries$Education = as.factor(salaries$Education)

#Variable Selection: Removed variables that contain redundant information or lack of information 
salaries = subset(salaries, select = c(company, level, title,
                                       totalyearlycompensation, location,
                                       yearsofexperience, yearsatcompany, tag,
                                       gender, Race, Education))
```

#### Model Selection Proccess 

##### 1. Split the Dataset into Train/Test Data

```{r message=FALSE, warning=FALSE}
#Importing library 
library(caret)

#Split the data 70-30 into train and test sets
set.seed(22)
trn_idx = createDataPartition(salaries$level, p = 0.7, list = F)
trn = salaries[trn_idx, ]
tst = salaries[-trn_idx, ]
```

##### 2. Selection of Predictors Using AIC/BIC Methodology

Please see Appendix for AIC/BIC forward and stepwise procedures

```{r}
#Model w/ 'totalyearlycompensation' as the response variable and all remaining variables as the predictors
salaries_model = lm(totalyearlycompensation ~ ., data = trn)

#Backward AIC
salaries_model_back_aic = step(salaries_model,
                               direction = "backward", trace = 0)

#Backward BIC
salaries_model_back_bic = step(salaries_model, direction = "backward",
                               k = log(nrow(trn)), trace = 0)
```

-- Using the AIC searching method, we derive a model that uses 7 of the 10 given predictors

   Selected Predictors: **<u>`r all.vars(formula(salaries_model_back_aic)[-1])`</u>**
  
-- Using the BIC searching method, we derive a model that uses 4 of the 10 given predictors

   Selected Predictors: **<u>`r all.vars(formula(salaries_model_back_bic)[-1])`</u>**

```{r}
#Performing anova test on the AIC and BIC models 
anova(salaries_model_back_bic, salaries_model_back_aic)
```

Based upon the results of our test, we calculate a p-value of **`r anova(salaries_model_back_bic, salaries_model_back_aic)[2, "Pr(>F)"]`** meaning that we reject the BIC model and accept the larger AIC model (`salaries_model_back_aic`). 

```{r}
#Checking the collinearity of the AIC model 
car::vif(salaries_model_back_aic)
```
None of the variance inflation factors are too high in `salaries_model_back_aic`, suggesting collinearity is not an issue. 

##### 3. Performing Model Transformations

```{r}
#Performing log response transformation to improve linearity
aic_model_log = lm(log(totalyearlycompensation) ~ company + yearsofexperience + title + level + gender + Race + Education, data = trn)

#Adding interactions to improve normality, linearity and constant variance
aic_model_trans = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + level + gender + Race + Education, data = trn)

#Performing anova test between the two models
anova(aic_model_log, aic_model_trans)
```
Based upon the results of our anova test, we calculated a p-value of < **`r anova(aic_model_log, aic_model_trans)[2, "Pr(>F)"]`** meaning that we reject the log model (`aic_model_log`) and prefer the larger transformation model (`aic_model_trans`). 

```{r}
#Removing influential data points from the model
aic_model_final = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + level + gender + Race + Education, data = trn, subset = cooks.distance(aic_model_trans) < 4 / length(cooks.distance(aic_model_trans)))
```

Cook's distance was employed to identify influential data points in `aic_model_trans`. A threshold was set, typically at 4/`n`, where `n` is the number of observations. Observations with a Cook's distance larger than this threshold were considered influential and removed.

The final model was saved as `aic_model_final`.

##### 4. Running Diagnostics

```{r message=FALSE, warning=FALSE}
#Importing libraries
library(car)
library(lmtest)
library(boot)
library(knitr)

#LOOCV RMSE Function - Gets the difference between the predicted values a model generates and the actual values 
get_loocv_rmse = function(model){
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

#Diagnostics
adj_initial = summary(salaries_model)$adj
adj_aic = summary(salaries_model_back_aic)$adj
adj_log = summary(aic_model_log)$adj
adj_final = summary(aic_model_final)$adj
loocv_rmse_final = get_loocv_rmse(aic_model_final)
shapiro_final = shapiro.test(resid(aic_model_final))$p.value
bp_final = test = bptest(aic_model_final)$p.value
loocv_rmse_final
```

##### 5. Percent Error 

```{r, message = FALSE, warning = FALSE}
#Get Percent Error Function - Calculates the percentage of error we expect our model to generate
get_percent_error = function(pred_salary, actual_salary){
  mean((abs(pred_salary - actual_salary) / pred_salary)) * 100
}

#Calculating average percent error of the test set
actual_salary = tst$totalyearlycompensation
pred_salary = exp(predict(aic_model_final, tst))
max_pe_salary = ifelse(max(actual_salary) > max(pred_salary), max(actual_salary), max(pred_salary))
percent_error = get_percent_error(pred_salary, actual_salary)
```

##### 6. Model Simulation  

```{r, message = FALSE, warning = FALSE}
#Simulation Set-Up
num_sims = 1000
rmse_trn = rep(0, num_sims)
rmse_tst = rep(0, num_sims)

#RMSE Function - Finds the difference between the predicted values and the actual values
rmse = function(y, y_hat){
  sqrt(sum((y - y_hat) ^ 2) / length(y))
}

#Storing Train RMSE and Test RMSE
for(i in 1:num_sims){
  sim_fit = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + level + gender + Race + Education, data = trn)
  
  rmse_trn[i] = rmse(trn$totalyearlycompensation, exp(predict(sim_fit, trn)))
  rmse_tst[i] = rmse(tst$totalyearlycompensation, exp(predict(sim_fit, tst)))
}
```

##### 7. Model Predictions  

```{r, message = FALSE, warning = FALSE}
#Predicting a person's salary based upon their level
level= c("L1", "L2", "L3", "L4", "L5", "L6", "L7", "L8")
amazon_salaries_level = rep(0, length(level))
google_salaries_level = rep(0, length(level))

for(i in 1:length(level)) {
  sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = level[i], title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = "White", Education = "Bachelor's Degree")))
  sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = level[i], title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = "White", Education = "Bachelor's Degree")))

  amazon_salaries_level[i] = sal1
  google_salaries_level[i] = sal2
}

#Predicting a person's salary based upon their years of experience
years = c(0, 5, 10, 15, 20, 25, 30, 35, 40)
amazon_salaries_years = rep(0, length(years))
google_salaries_years = rep(0, length(years))

for(i in 1:length(years)) {
  sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L3", title = "Software Engineer", yearsofexperience = years[i], gender = "Male", Race = "White", Education = "Bachelor's Degree")))
  sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L3", title = "Software Engineer", yearsofexperience = years[i], gender = "Male", Race = "White", Education = "Bachelor's Degree")))

  amazon_salaries_years[i] = sal1
  google_salaries_years[i] = sal2
}

#Predicting a person's salary based upon their title
title = c("Sales", "Human Resources", "Product Manager", "Software Engineer", "Data Scientist")
amazon_salaries_title = rep(0, length(title))
google_salaries_title = rep(0, length(title))

for(i in 1:length(title)) {
  sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L3", title = title[i], yearsofexperience = 0, gender = "Male", Race = "White", Education = "Bachelor's Degree")))
  sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L3", title = title[i], yearsofexperience = 0, gender = "Male", Race = "White", Education = "Bachelor's Degree")))

  amazon_salaries_title[i] = sal1
  google_salaries_title[i] = sal2
}

#Initializing variables for predicting a persons salary based upon their race
race = c("White", "Black", "Hispanic", "Asian", "Two Or More")
amazon_salaries_race = rep(0, length(unique(salaries$Race)))
google_salaries_race = rep(0, length(unique(salaries$Race)))

for(i in 1:length(unique(salaries$Race))) {
  sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L3", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
  sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L3", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))

  amazon_salaries_race[i] = sal1
  google_salaries_race[i] = sal2
}

# Initializing variables for predicting a person's salary based upon their gender
gender = c("Male", "Female")
amazon_salaries_gender = rep(0, length(gender))
google_salaries_gender = rep(0, length(gender))

for(i in 1:length(gender)) {
  sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L3", title = "Software Engineer", yearsofexperience = 0, gender = gender[i], Race = "White", Education = "Bachelor's Degree")))
  sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L3", title = "Software Engineer", yearsofexperience = 0, gender = gender[i], Race = "White", Education = "Bachelor's Degree")))

  amazon_salaries_gender[i] = sal1
  google_salaries_gender[i] = sal2
}

#Prediction of how much  more entry level male will be paid more than female counterpart 
male_entry_salary = amazon_salaries_gender[1] + google_salaries_gender[1]
female_entry_salary = amazon_salaries_gender[2] + google_salaries_gender[2]
male_vs_female_salary = round(male_entry_salary / female_entry_salary - 1, 2) 

# Initializing variables for predicting a person's salary based upon their education level
education_levels = c("Highschool", "Bachelor's Degree", "Master's Degree", "PhD", "Some College")
amazon_salaries_education = rep(0, length(education_levels))
google_salaries_education = rep(0, length(education_levels))

for(i in 1:length(education_levels)) {
  sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L3", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = "White", Education = education_levels[i])))
  sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L3", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = "White", Education = education_levels[i])))

  amazon_salaries_education[i] = sal1
  google_salaries_education[i] = sal2
}

##Predicted L3 salaries based on company 
amazon_l1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L3", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = "White", Education = "Bachelor's Degree"), interval = "prediction"))[1]
google_l1 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L3", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = "White", Education = "Bachelor's Degree"), interval = "prediction"))[1]
```
***

### <u>Results</u>

#### Diagnostics

##### 1. Diagnostics Table

```{r}
row_names = c("Average RMSE Train", "Average RMSE Test", "Percent Error")
column_names = c("Statistic", "Value")
diagnostics = c(mean(rmse_trn), mean(rmse_tst), percent_error)
df_results = data.frame(row_names, diagnostics)
kable(df_results, "simple", col.names = column_names)
```

##### 2. Goodness-Of-Fit

Comparison of Adjusted $R^2$ through model selection: 
```{r}
row_names = c("Initial Model", "AIC Model","Log Response Model", "Final Model")
column_names = c("Model", "Adjusted R")
adj_r = c(adj_initial, adj_aic, adj_log, adj_final)
df_results = data.frame(row_names, adj_r)
kable(df_results, "simple", col.names = column_names)
```

##### 3. Q-Q Plots

Comparison of the progression of Normal Q-Q plots through model selection:
```{r, fig.dim = c(12, 10)}
par(mfrow = c(1,3))

# Q-Q plot of initial model without log response transformation
qqnorm(resid(salaries_model_back_aic), main = "Normal Q-Q Plot Before Log Response", col = "darkgrey")
qqline(resid(salaries_model_back_aic), col = "dodgerblue", lwd = 2)

# Q-Q plot after log response transformation
qqnorm(resid(aic_model_log), main = "Normal Q-Q Plot After Log Response", col = "darkgrey")
qqline(resid(aic_model_log), col = "dodgerblue", lwd = 2)

# Q-Q plot after all transformations
qqnorm(resid(aic_model_final), main = "Normal Q-Q Plot After All Transformations", col = "darkgrey")
qqline(resid(aic_model_final), col = "dodgerblue", lwd = 2)
```
As more transformations were added to the model the wildness of the tails remained largely unchanged, which indicates that our dataset likely does not follow a normal distribution. 

##### 4. Residuals vs. Fitted Plots

Comparison of the progression of Fitted Vs. Residuals plots through model selection:
```{r, fig.dim = c(12, 10)}
par(mfrow = c(1,3))

#Residuals vs Fitted plot of initial model without log response transformation
plot(fitted(salaries_model_back_aic), resid(salaries_model_back_aic), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Resids Before Log Response")
abline(h = 0, col = "darkorange", lwd = 2)

#Residuals vs Fitted plot after log response transformation
plot(fitted(aic_model_log), resid(aic_model_log), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Resids After Log Response")
abline(h = 0, col = "darkorange", lwd = 2)

#Residuals vs Fitted plot after all transformations
plot(fitted(aic_model_final), resid(aic_model_final), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Resids After All Transformations")
abline(h = 0, col = "darkorange", lwd = 2)
```

##### 5. Percent Error - Fitted vs. Actual Salaries

```{r}
plot(pred_salary, actual_salary,
     col = "darkgrey",
     xlab = "Predicted Salaries",
     ylab = "Actual Salaries",
     main = "Predicted vs. Actual Salaries",
     xlim = c(0, max_pe_salary),
     ylim = c(0, max_pe_salary)
     )
abline(0, 1, col = "dodgerblue")
```

##### 6. Practical Application of Model 

Comparison Plots of Salaries Across Different Factors:
```{r graph1, fig.dim = c(12, 10)}
# Define common y-axis limits
max_salary = max(c(amazon_salaries_level, google_salaries_level))*1.1

# Plot
par(mfrow = c(1,2))
barplot(amazon_salaries_level, names.arg = level, col=rainbow(length(amazon_salaries_level)), 
        main = "AMZN: Salary Based on Level", xlab = "Level", ylab = "Total Compensation", ylim = c(0, max_salary))
barplot(google_salaries_level, names.arg = level, col=rainbow(length(google_salaries_level)), 
        main = "GOOG: Salary Based on Level", xlab = "Level", ylab = "Total Compensation", ylim = c(0, max_salary))
```

Graph 1 - The graph above, displays the expected salary of Male individuals with the exact same qualifications but each individual is of a different level.

```{r, fig.dim = c(12, 10)}
# Define common y-axis limits
max_salary = max(c(amazon_salaries_years, google_salaries_years))*1.1

# Plot
par(mfrow = c(1,2))
barplot(amazon_salaries_years, names.arg = years, col=rainbow(length(amazon_salaries_years)), 
        main = "AMZN: L3 Salary Based on Years of Experience", xlab = "Years of Experience", ylab = "Total Compensation", ylim = c(0, max_salary))
barplot(google_salaries_years, names.arg = years, col=rainbow(length(google_salaries_years)), 
        main = "GOOG: L3 Salary Based on Years of Experience", xlab = "Years of Experience", ylab = "Total Compensation", ylim = c(0, max_salary))
```

Graph 2 - The graph above, displays the expected Entry Level (L3) salary of Male individuals with the exact same qualifications but each individual has different years of experience.

```{r, fig.dim = c(12, 8)}
# Define common y-axis limits
max_salary = max(c(amazon_salaries_title, google_salaries_title))*1.1

# Plot
par(mfrow = c(1,2))
barplot(amazon_salaries_title, names.arg = title, col=rainbow(length(amazon_salaries_title)), 
        main = "AMZN: L3 Salary Based on Title", xlab = "Title", ylab = "Total Compensation", ylim = c(0, max_salary), cex.names = .6)
barplot(google_salaries_title, names.arg = title, col=rainbow(length(google_salaries_title)), 
        main = "GOOG: L3 Salary Based on Title", xlab = "Title", ylab = "Total Compensation", ylim = c(0, max_salary), cex.names = .6)
```

Graph 3 - The graph above, displays the expected Entry Level (L3) salary of Male individuals with the exact same qualifications but each individual has a different job title (chosen from the subset of possible titles.)

```{r, fig.dim = c(12, 8)}
# Define common y-axis limits
max_salary = max(c(amazon_salaries_race, google_salaries_race))*1.1

# Plot
par(mfrow = c(1,2))
barplot(amazon_salaries_race, names.arg = race, col=rainbow(length(amazon_salaries_race)), 
        main = "AMZN: L3 Salary Based on Race", xlab = "Race", ylab = "Total Compensation", ylim = c(0, max_salary))
barplot(google_salaries_race, names.arg = race, col=rainbow(length(google_salaries_race)), 
        main = "GOOG: L3 Salary Based on Race", xlab = "Race", ylab = "Total Compensation", ylim = c(0, max_salary))
```

Graph 4 - The graph above, displays the expected Entry Level (L3) salary of Male individuals with the exact same qualifications but each individual is of a different race. 

```{r, fig.dim = c(12, 10)}
# Define common y-axis limits
max_salary = max(c(amazon_salaries_gender, google_salaries_gender))*1.1

# Plot
par(mfrow = c(1,2))
barplot(amazon_salaries_gender, names.arg = gender, col=c("blue", "red"), 
        main = "AMZN: L3 Salary Based on Gender", xlab = "Gender", ylab = "Total Compensation", ylim = c(0, max_salary))
barplot(google_salaries_gender, names.arg = gender, col=c("blue", "red"), 
        main = "GOOG: L3 Salary Based on Gender", xlab = "Gender", ylab = "Total Compensation", ylim = c(0, max_salary))
```

Graph 5 - The graph above, displays the expected Entry Level (L3) salary of individuals with the exact same qualifications and race but each individual is of a different gender. 

```{r, fig.dim = c(12, 8)}
# Define common y-axis limits
max_salary = max(c(amazon_salaries_education, google_salaries_education))*1.1

# Plot
par(mfrow = c(1,2))
barplot(amazon_salaries_education, names.arg = education_levels, col=rainbow(length(amazon_salaries_education)), 
        main = "AMZN: L3 Salary Based on Education Level", xlab = "Education", ylab = "Total Compensation", ylim = c(0, max_salary),
        cex.names = .6)
barplot(google_salaries_education, names.arg = education_levels, col=rainbow(length(google_salaries_education)), 
        main = "GOOG: L3 Salary Based on Education Level", xlab = "Education", ylab = "Total Compensation", ylim = c(0, max_salary), 
        cex.names = .6)
```

Graph 6 - The graph above, displays the expected Entry Level (L3) salary of individuals of the same race but each individual has a different level of educational experience. 

***

### <u>Discussion</u>

```{r include=FALSE}
options(scipen = 999)  
```

#### Understanding the Final Model

Our final model, `aic_model_final`, includes interactions between company, years of experience, and title, along with other factors such as level, gender, race, and education. The model was carefully constructed through multiple steps including log transformation, interaction exploration, and removal of influential data points.

We utilized the model to analyze different factors and draw comparisons. Below is a summary of the conclusions derived:

##### 1. General Trends
- **Google's Salary vs. Amazon's**: Google tends to offer higher salaries than Amazon (Graph 1)
- **Impact of Levels on Salary**: Salaries increase as levels rise (Graph 2)
- **Tech vs. Non-tech Roles**: Tech roles command higher salaries compared to non-tech roles (Graph 3).

##### 2.  Social Factors
- **Race**: At both Amazon and Google, the highest predicted earners are individuals who are Asian or of Two or More races (Graph 4).
- **Gender**: Males at both Amazon and Google earn approximately 4% more than their Female counterparts (Graph 5).
- **Education**: Both companies predict the highest starting entry-level salaries for Ph.D. students; however, the second-highest predicted salary is for those with only some college experience (Graph 6).


#### Key Findings

##### 1. Interactions, Transformations and Subset Selection

The interactions between company, years of experience, and title suggest that the relationship between these factors and total yearly compensation is not simply additive. This reflects the complexity of compensation structures in the real world, where various elements can synergistically affect the outcome. Log transformation of the total yearly compensation helped to linearize the relationship with predictors. Additionally, the use of Cook's distance to exclude influential points contributed to model robustness. 
  
In our analysis, the Q-Q normal plots evolved across three models. In the first plot, the pattern formed by the plot points was nearly parallel to the diagonal line, with a wide y-axis range, indicating non-normality and potential outliers. As we moved to the second model, the y-axis range narrowed, and the pattern of the points started to resemble a more typical diagonal alignment, reflecting an improvement in normality. The third model continued this trend, though the most substantial shift occurred between the first and second models. These transitions signify our progression toward satisfying the normality assumption in the residual errors, a critical aspect in linear regression modeling.
 
Additionally, the first Residuals vs. Fitted Plot shows residuals clustering together, indicating potential non-linearity. In the second plot, the residuals begin to disperse, suggesting an improvement in linearity. The third plot further demonstrates this trend, with residuals more randomly scattered, adhering better to the assumptions of linear regression. The progression across these plots illustrates the model's refinement and increased ability to capture the underlying relationship in the data.

##### 2. Model Fit

Through the variable section process and utilizing model transformation techniques, our model achieved a higher Adjusted R (`r adj_initial` -> `r adj_final`), which indicates that our final model improved in calculating fitted values. ****RMSE discussion***

##### 3. Accuracy 

The final model we have selected demonstrated an accuracy rating of **`r 100 - percent_error`%**. This is indicative of the model's ability to fit the data, but it's worth noting that there may be room for further refinement and improvement. 

The Actual Vs. Predicted Salaries plot illustrates the correlation between our final model's salary predictions and the actual salaries. The points are largely concentrated around the diagonal line, where predicted values would equal actual values. This concentration signifies that the predictions are generally close to the actual figures, indicating the model's robustness and accuracy in predicting salaries. 

#### Limitations and Areas for Improvement

There were various lessons learned while conducting this project. The first challenge the team encountered was during the initial data preparation phase. Because the dataset was a) crowd-sourced and b) scraped from a website, this led to many errors and inconsistencies which required vigorous data cleaning. The team used techniques including clustering, spell checks, removing missing fields, and cross validation in order to standardize the dataset. Ultimately, although we were able to produce a dataset fit for analysis, we were still limited by needing to rely on a user's "standard of truth" instead of an official or confirmed source. For example, a user could easily have input random attributes and we would have no way of knowing.

This leads to the next issue we faced, which was that the raw data was not evenly distributed across the various attributes. The data was heavily skewed towards mid-level entries, and we did not have data for nearly as many entry-level or executive-level positions.  Additionally, there were far more entries for Amazon than Google employees. Thus, this presented a challenge when trying to build the model under LINE assumptions. For example, two individuals with the exact same given parameters except for the `company` variable for had drastically different L1 predicted salaries.

- Amazon: $`r round(amazon_l1, 2)`
- Google: $`r round(google_l1, 2)`

In the future, there are several areas of improvement we'd explore:

- Gather more data from levels.fyi to ensure more even distribution and representation of salaries.
- Use an official source of employee data such as a database from the U.S. Department of Labor.
- Explore other models and techniques outside of linear regression to perhaps find a better model for prediction.

#### Conclusion

The final model `aic_model_final` represents an intricate understanding of how various factors like company, years of experience, title, level, gender, race, and education interact to influence total yearly compensation. This is not only a strategic tool for HR professionals but also a subject of great interest for data science students like us, and potentially a valuable resource for sociological studies.

The inclusion of categorical variables such as gender, race, and education may imply societal or industry-specific trends affecting salary. These factors should be interpreted with caution and in the context of broader research and understanding. Their realization in our model adds depth by highlighting how they can significantly impact total yearly compensation even in tech companies. This goes beyond mere corporate strategy, offering insights that can be applied in social science research to understand biases and inequalities in the workplace.

Individuals seeking jobs, organizations aiming to design more tailored and competitive compensation plans, and researchers examining societal trends can all benefit from this model. The nuanced understanding of how different variables interplay offers a unique lens into the underlying dynamics of the job market.

However, the model's utility is not without caveats. Its specific interactions and potential biases in data collection may limit its general application and scalability. The handling of sensitive areas such as gender and race requires thoughtful consideration, ensuring that insights align with ethical guidelines.

In conclusion, `aic_model_final` is a robust and multifaceted tool. Its applications are broad, ranging from individual and organizational decision-making to broader sociological analysis. It must be leveraged thoughtfully to realize its full potential and contribute to a more informed and equitable society.

***

### <u>Appendix</u> 

AIC/BIC Models using forward and stepwise procedures 
```{r}
#Forward AIC
salaries_model_forw_aic = step(salaries_model, 
                               scope = totalyearlycompensation ~ company + level +
                               title + yearsofexperience + yearsatcompany + tag +
                               gender + Race + Education + location,
                               direction = "forward", trace = 0)

#Forward BIC
salaries_model_forw_bic = step(salaries_model, 
                               scope = totalyearlycompensation ~ company + level +
                               title + yearsofexperience + yearsatcompany + tag +
                               gender + Race + Education + location,
                               direction = "forward", k = log(nrow(salaries)), trace = 0)

#Stepwise AIC
salaries_model_both_aic = step(salaries_model, 
                               scope = totalyearlycompensation ~ company + level +
                               title + yearsofexperience + yearsatcompany + tag +
                               gender + Race + Education + location,
                               direction = "both", trace = 0)

#Stepwise BIC
salaries_model_both_bic = step(salaries_model, 
                               scope = totalyearlycompensation ~ company + level +
                               title + yearsofexperience + yearsatcompany + tag +
                               gender + Race + Education + location,
                               direction = "both", k = log(nrow(salaries)), trace = 0)
```

Unused Statistic's 
```{r}
row_names = c("LOOCV-RMSE", "Shapiro Test", "BP Test")
column_names = c("Statistic", "Value")
diagnostics = c(loocv_rmse_final, shapiro_final, bp_final)
df_results = data.frame(row_names, diagnostics)
kable(df_results, "simple", col.names = column_names)
```

By: Nicholas O. Brown, Ellie Jung, Angela Mei

***

