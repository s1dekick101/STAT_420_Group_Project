---
title: "Data Analysis of Tech. Salaries at Amazon and Google"
author: "The Statisticians"
date: "`r Sys.Date()`"
output:
  html_document: 
    theme: readable
    toc: yes
urlcolor: cyan
---

### <u>Introduction</u>

As data science students, we're intrigued by the compensation structures within leading tech companies like Amazon and Google. To delve into this interest, we're undertaking a project to analyze a dataset of 12,647 salary records from these companies, with an aim to construct a predictive model for annual total compensation.

This dataset, `Levels-Fyi-Salary-Data-Cleaned.csv`, provides a unique and in-depth perspective into the salary structures of numerous top-tier companies. The dataset encompasses 28 variables, covering a variety of aspects such as company, level, title, location, years of experience, years at the company, and various demographic factors including gender and education level. Of particular interest to us is the `totalyearlycompensation` variable, which will serve as the response variable in our analysis.

Our interest in this dataset is driven by our curiosity about the factors that influence annual compensation in top companies. We aim to identify the key variables and their interactions that significantly impact salary levels. This would provide insights that could be invaluable to a variety of stakeholders, from job seekers and employees to human resource professionals and policymakers.

The primary goal of creating a model with this data is to predict the `totalyearlycompensation` based on a set of predictor variables. This model will help us understand how different variables, including categorical ones like `company` and numeric ones such as `yearsofexperience` and `basesalary`, contribute to the total yearly compensation of an employee. Through this process, we also hope to identify potential trends, anomalies, or points of interest that could provide further avenues for exploration and analysis.

***

### <u>Methods</u>

-- We choose the following model... `(PLACE HOLDER)`

```{r message=FALSE, warning=FALSE}
#Loading dataset
library(readr)
library(stringr)
salaries = read_csv("Levels-Fyi-Salary-Data-Cleaned-US.csv")

#Remove NA records
salaries = na.omit(salaries)

#Create new column 'State' which only shows the Convert to State
salaries$state = str_sub(salaries$location,-2,-1)

#Changing some predictors to factors
salaries$company = as.factor(salaries$company)
salaries$level = as.factor(salaries$level)
salaries$title = as.factor(salaries$title)
salaries$location = as.factor(salaries$location)
salaries$state = as.factor(salaries$state)
salaries$gender = as.factor(salaries$gender)
salaries$Race = as.factor(salaries$Race)
salaries$Education = as.factor(salaries$Education)

#Feel free to uncomment until we get confirmation from TA on removing columns or not
#Variable Selection: Removed variables that contained redundant information 
#salaries = subset(salaries, select = c(company, level, title,
#                                       totalyearlycompensation,
#                                       yearsofexperience, yearsatcompany, tag,
#                                       basesalary, stockgrantvalue, bonus,
#                                       gender, Race, Education, state))

#Variable Selection: Removed variables that contained redundant information 
salaries = subset(salaries, select = c(company, level, title,
                                       totalyearlycompensation,
                                       yearsofexperience, yearsatcompany, tag,
                                       gender, Race, Education, state))
```

```{r}
# Placeholder and we will just put the model we actually use here 
model = 2
```


***

### <u>Results</u>


***

### <u>Discussion</u>


***

### <u>Appendix</u> 

Linear Model that includes all predictors
```{r}
salaries_model = lm(totalyearlycompensation ~ ., data = salaries)
```

AIC/BIC Models
```{r}
#Didnt use p but n was used for model BIC models  
#p = length(coef(salaries_model))
n = length(resid(salaries_model))

#Backward AIC
salaries_model_back_aic = step(salaries_model,
                               direction = "backward", trace = 0)

#Backward BIC
salaries_model_back_bic = step(salaries_model, direction = "backward",
                               k = log(n), trace = 0)

salaries_model_start = lm(totalyearlycompensation ~ 1, data = salaries)

#Forward AIC
salaries_model_forw_aic = step(salaries_model_start, 
                               scope = totalyearlycompensation ~ company + level +
                               title + yearsofexperience + yearsatcompany + tag +
                               gender + Race + Education + state,
                               direction = "forward", trace = 0)

#Forward BIC
salaries_model_forw_bic = step(salaries_model_start, 
                               scope = totalyearlycompensation ~ company + level +
                               title + yearsofexperience + yearsatcompany + tag +
                               gender + Race + Education + state,
                               direction = "forward", k = log(n), trace = 0)

#Stepwise AIC
salaries_model_both_aic = step(salaries_model_start, 
                               scope = totalyearlycompensation ~ company + level +
                               title + yearsofexperience + yearsatcompany + tag +
                               gender + Race + Education + state,
                               direction = "both", trace = 0)

#Stepwise BIC
salaries_model_both_bic = step(salaries_model_start, 
                               scope = totalyearlycompensation ~ company + level +
                               title + yearsofexperience + yearsatcompany + tag +
                               gender + Race + Education + state,
                               direction = "both", k = log(n), trace = 0)


#AIC derives a model using 9 of the 10 initial inputted predictors
#salaries_model_back_aic
#salaries_model_forw_aic
#salaries_model_both_aic

#BIC derives a model using 4 of the 10 initial inputted predictors
#salaries_model_back_bic
#salaries_model_forw_bic
#salaries_model_both_bic
```

Model 2 
```{r}
library(lmtest)
# salaries_model_add = lm(log(totalyearlycompensation) ~ yearsatcompany * title * state * level, data = salaries)
# 
# summary(salaries_model_add)
# 
# salaries_model_fix = lm(log(totalyearlycompensation) ~ yearsatcompany * title * state * level, data = salaries, subset = cooks.distance(salaries_model_add) < 4 / length(cooks.distance(salaries_model_add)))
# 
# hist(resid(salaries_model_fix))
# 
# #salaries_model_int = lm(totalyearlycompensation ~ level * title * yearsofexperience * yearsatcompany, data = salaries)
# 
# #anova(salaries_model_add, salaries_model_int)
# #summary(salaries_model_int)
# 
# #salaries_model_three_int = lm(totalyearlycompensation ~ company * level * yearsofexperience, data = salaries)
# 
# qqnorm(resid(salaries_model_fix))
# qqline(resid(salaries_model_fix))
# plot(fitted(salaries_model_fix), resid(salaries_model_fix))
# abline(h=0)
# shapiro.test(resid(salaries_model_fix))
# bptest(salaries_model_fix)
#anova(salaries_model_add, salaries_model_two_int)

#anova(salaries_model_two_int, salaries_model_three_int)

```


Predictor/Response Transforamtion Models
```{r}
# Check if there are any 0 or negative values in the predictors and response variable
sum(salaries$yearsofexperience <= 0, na.rm = TRUE)
sum(salaries$yearsatcompany <= 0, na.rm = TRUE)
sum(salaries$totalyearlycompensation <= 0, na.rm = TRUE)

# Add a small constant before log transformation
salaries$yearsofexperience_log = log1p(salaries$yearsofexperience)
salaries$yearsatcompany_log = log1p(salaries$yearsatcompany)
salaries$totalyearlycompensation_log = log1p(salaries$totalyearlycompensation)

# Create a model with transformed predictors
model_predictor_transformed = lm(totalyearlycompensation ~ yearsofexperience_log + yearsatcompany_log, data = salaries)
summary(model_predictor_transformed)

# Create a model with transformed response
model_response_transformed = lm(totalyearlycompensation_log ~ yearsofexperience + yearsatcompany, data = salaries)
summary(model_response_transformed)

# Plot for Predictor Transformed Model
plot(salaries$totalyearlycompensation, predict(model_predictor_transformed), main="Predictor Transformed Model",
     xlab="Actual Total Yearly Compensation", ylab="Predicted Total Yearly Compensation")

# Plot for Response Transformed Model
plot(expm1(salaries$totalyearlycompensation_log), expm1(predict(model_response_transformed)), main="Response Transformed Model",
     xlab="Actual Total Yearly Compensation", ylab="Predicted Total Yearly Compensation")


# Set graphical parameters for a 2x2 grid of plots
par(mfrow = c(2, 2), mar = c(4, 4, 2, 1))

print("Predictor Transformed Model")

# Predictor Transformed Model Residuals
residuals_predictor_transformed = residuals(model_predictor_transformed)

# Histogram
hist(residuals_predictor_transformed, main = "Histogram of Residuals", xlab = "Residuals", col = "skyblue")

# Normal Q-Q plot
qqnorm(residuals_predictor_transformed, main = "Normal Q-Q plot")
qqline(residuals_predictor_transformed, col = "red", lwd = 2)

# Response Transformed Model Residuals
residuals_response_transformed = residuals(model_response_transformed)

# Histogram
hist(residuals_response_transformed, main = "Histogram of Residuals", xlab = "Residuals", col = "skyblue")

# Normal Q-Q plot
qqnorm(residuals_response_transformed, main = "Normal Q-Q plot")
qqline(residuals_response_transformed, col = "red", lwd = 2)

# Reset graphical parameters to default
par(mfrow = c(1, 1), mar = c(5, 4, 4, 2) + 0.1)

```

Model Selection
```{r}

```



By: Nicholas O. Brown, Ellie Jung, Angela Mei

***

