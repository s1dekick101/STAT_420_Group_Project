---
title: "Data Analysis of Tech. Salaries at Amazon and Google"
author: "The Statisticians"
date: "`r Sys.Date()`"
output:
  html_document: 
    theme: readable
    toc: yes
urlcolor: cyan
---

### <u>Introduction</u>

As data science students, we're intrigued by the compensation structures within leading tech companies like Amazon and Google. To delve into this interest, we're undertaking a project to analyze a dataset of 12,647 salary records from these two companies, with an aim to construct a predictive model for annual total compensation. This dataset was originally created on Kaggle, with data sourced from scraping levels.fyi.

This dataset, `Levels-Fyi-Salary-Data-Cleaned-US.csv`, provides a unique and in-depth perspective into the salary structures of numerous top-tier companies. The dataset encompasses 28 variables, covering a variety of aspects such as company, level, title, location, years of experience, years at the company, and various demographic factors including gender and education level. Of particular interest to us is the `totalyearlycompensation` variable, which will serve as the response variable in our analysis.

Our interest in this dataset is driven by our curiosity about the factors that influence annual compensation in top companies. We aim to identify the key variables and their interactions that significantly impact salary levels. This would provide insights that could be invaluable to a variety of stakeholders, from job seekers and employees to human resource professionals and policymakers.

The primary goal of creating a model with this data is to predict the `totalyearlycompensation` based on a set of predictor variables. This model will help us understand how different variables, including categorical ones like `level` and numeric ones such as `yearsofexperience` and `yearsatcompany`, contribute to the total yearly compensation of an employee. Through this process, we also hope to identify potential trends, anomalies, or points of interest that could provide further avenues for exploration and analysis.

***

### <u>Methods</u>

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(digits = 4)
```


#### Description of the original data file
- `timestamp`: Timestamp of data entry
- `company`: The company the employee works for, either Amazon or Google
- `level`: The rank of the employee, ranging from L1 through L10
- `title`: The job title of the employee
- `location`: The city, state that the employee resides in
- `totalyearlycompensation`: The total yearly compensation of the employee
- `yearsofexperience`: The total years of working experience of the employee
- `yearsatcompany`: The years at the company of the employee
- `tag`: A tag for additional information
- `basesalary`: Employee's annual base salary
- `stockgrantvalue`: Employee's annual stock grant value
- `bonus`: Employee's annual bonus
- `otherdetails`: Other details
- `cityid`: City id
- `dmaid`: Dma id
- `rowNumber`: Row number
- `Masters_Degree`: A dummy variable indicating employee's level of education
- `Bachelors_Degree`: A dummy variable indicating employee's level of education
- `Doctorate_Degree`: A dummy variable indicating employee's level of education
- `Highschool`: A dummy variable indicating employee's level of education
- `Some_College`: A dummy variable indicating employee's level of education
- `Race_Asian`: A dummy variable indicating employee's race
- `Race_White`: A dummy variable indicating employee's race
- `Race_Two_Or_More`: A dummy variable indicating employee's race
- `Race_Black`: A dummy variable indicating employee's race
- `Race_Hispanic`: A dummy variable indicating employee's race
- `gender`: The gender of the employee
- `Race`: The race of the employee
- `Education`: The education level of the employee

#### Data Pre-Processing 

First, we had to clean and prepare our data to make it fit for analysis. We removed any records with missing values, and converted all categorical variables into factors. We chose to exclude certain columns from our final dataset for these reasons: 

- The column was not a descriptive attribute of the employee (`timestamp`, `cityid`, `dmaid`, `rowNumber`) 
- The column was a dummy variable with redundant data also stored in another column (`Masters_Degree`, `Bachelors_Degree`, `Doctorate_Degree`, `Highschool`, `Some_College`, `Race_Asian`, `Race_White`, `Race_Two_Or_More`, `Race_Black`, `Race_Hispanic`, `otherdetails`)

Lastly, we excluded columns `basesalary`, `stockgrantvalue`, and `bonus` as we discovered that these fields were providing contradictory data. These three values are supposed to sum up to `totalyearlycompensation`; however, this was not the case the majority of the time. This is most likely due to faulty or missing user entry.

```{r message=FALSE, warning=FALSE}
#Loading dataset and importing libraries
library(readr)
library(stringr)
salaries = read_csv("Levels-Fyi-Salary-Data-Cleaned-US.csv")

#Remove NA records
salaries = na.omit(salaries)

#Changing some predictors to factors
salaries$company = as.factor(salaries$company)
salaries$level = as.factor(salaries$level)
salaries$title = as.factor(salaries$title)
salaries$location = as.factor(salaries$location)
salaries$gender = as.factor(salaries$gender)
salaries$Race = as.factor(salaries$Race)
salaries$Education = as.factor(salaries$Education)

#Variable Selection: Removed variables that contain redundant information or lack of information 
salaries = subset(salaries, select = c(company, level, title,
                                       totalyearlycompensation, location,
                                       yearsofexperience, yearsatcompany, tag,
                                       gender, Race, Education))
```

#### Model Selection Proccess 

##### 1. Split the Dataset into Train/Test Data

```{r}
#Importing library 
library(caret)

#Split the data 70-30 into train and test sets
set.seed(22)
trn_idx = createDataPartition(salaries$level, p = 0.7, list = F)
trn = salaries[trn_idx, ]
tst = salaries[-trn_idx, ]
```

##### 2. Selection of Predictors Using AIC/BIC Methodology

```{r}
#Model w/ 'totalyearlycompensation' as the response variable and all remaining variables as the predictors
salaries_model = lm(totalyearlycompensation ~ ., data = trn)

#Backward AIC
salaries_model_back_aic = step(salaries_model,
                               direction = "backward", trace = 0)

#Backward BIC
salaries_model_back_bic = step(salaries_model, direction = "backward",
                               k = log(nrow(trn)), trace = 0)
```

-- Using the AIC searching method, we derive a model that uses 7 of the 10 given predictors

   Selected Predictors: **<u>`r all.vars(formula(salaries_model_back_aic)[-1])`</u>**
  
-- Using the BIC searching method, we derive a model that uses 4 of the 10 given predictors

   Selected Predictors: **<u>`r all.vars(formula(salaries_model_back_bic)[-1])`</u>**

Please see Appendix for forward and stepwise procedures.
  

```{r}
#Performing anova test on the AIC and BIC models 
anova(salaries_model_back_bic, salaries_model_back_aic)
```

Based upon the results of our test, we calculate a p-value of **`r anova(salaries_model_back_bic, salaries_model_back_aic)[2, "Pr(>F)"]`** meaning that we reject the BIC model and accept the larger AIC model (`salaries_model_back_aic`). 

```{r}
#Checking the collinearity of the AIC model 
car::vif(salaries_model_back_aic)
```
None of the variance inflation factors are too high in `salaries_model_back_aic`, suggesting collinearity is not an issue. 

##### 3. Performing Model Transformations

```{r}
#Performing log response transformation to improve linearity
aic_model_log = lm(log(totalyearlycompensation) ~ company + yearsofexperience + title + level + gender + Race + Education, data = trn)

#Adding interactions to improve normality, linearity and constant variance
aic_model_trans = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + level + gender + Race + Education, data = trn)

#Performing anova test between the two models
anova(aic_model_log, aic_model_trans)
```
Based upon the results of our anova test, we calculated a p-value of < **`r anova(aic_model_log, aic_model_trans)[2, "Pr(>F)"]`** meaning that we reject the log model (`aic_model_log`) and prefer the larger transformation model (`aic_model_trans`). 

```{r}
#Removing influential data points from the model
aic_model_final = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + level + gender + Race + Education, data = trn, subset = cooks.distance(aic_model_trans) < 4 / length(cooks.distance(aic_model_trans)))
```

Cook's distance was employed to identify influential data points in `aic_model_trans`. A threshold was set, typically at 4/`n`, where `n` is the number of observations. Observations with a Cook's distance larger than this threshold were considered influential and were removed. The final model was saved as `aic_model_final`.

##### 4. Run Diagnostics

```{r message=FALSE, warning=FALSE}
#Importing libraries
library(car)
library(lmtest)
library(boot)
library(knitr)

#LOOCV RMSE Function - ... 
get_loocv_rmse = function(model){
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

#Diagnostics
adj_initial = summary(salaries_model)$adj
adj_aic = summary(salaries_model_back_aic)$adj
adj_log = summary(aic_model_log)$adj
adj_final = summary(aic_model_final)$adj
loocv_rmse_final = get_loocv_rmse(aic_model_final)
shapiro_final = shapiro.test(resid(aic_model_final))$p.value
bp_final = test = bptest(aic_model_final)$p.value
```

##### 5. Percent Error 

```{r, message = FALSE, warning = FALSE}
get_percent_error = function(pred_salary, actual_salary){
  mean((abs(pred_salary - actual_salary) / pred_salary)) * 100
}

#Calculating average percent error of the test set
actual_salary = tst$totalyearlycompensation
pred_salary = exp(predict(aic_model_final, tst))
max_pe_salary = ifelse(max(actual_salary) > max(pred_salary), max(actual_salary), max(pred_salary))
percent_error = get_percent_error(pred_salary, actual_salary)
```

##### 6.Model Simulation  

```{r, message = FALSE, warning = FALSE}
#Simulation Set-Up
num_sims = 1000
rmse_trn = rep(0, num_sims)
rmse_tst = rep(0, num_sims)

rmse = function(y, y_hat){
  sqrt(sum((y - y_hat) ^ 2) / length(y))
}

#Storing Train RMSE and Test RMSE
for(i in 1:num_sims){
  sim_fit = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + level + gender + Race + Education, data = trn)
  
  rmse_trn[i] = rmse(trn$totalyearlycompensation, exp(predict(sim_fit, trn)))
  rmse_tst[i] = rmse(tst$totalyearlycompensation, exp(predict(sim_fit, tst)))
}
```

##### 7. Model Predictions  

```{r, message = FALSE, warning = FALSE}
#Initializing variables for predicting a persons salary based upon their race
race = c("White", "Black", "Hispanic", "Asian", "Two Or More")
amazon_salaries_race = rep(0, length(unique(salaries$Race)))
google_salaries_race = rep(0, length(unique(salaries$Race)))

for(i in 1:length(unique(salaries$Race))) {
  sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))
  sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree")))

  amazon_salaries_race[i] = sal1
  google_salaries_race[i] = sal2
}

# Initializing variables for predicting a person's salary based upon their gender
gender = c("Male", "Female")
amazon_salaries_gender = rep(0, length(gender))
google_salaries_gender = rep(0, length(gender))

for(i in 1:length(gender)) {
  sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = gender[i], Race = "White", Education = "Bachelor's Degree")))
  sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = gender[i], Race = "White", Education = "Bachelor's Degree")))

  amazon_salaries_gender[i] = sal1
  google_salaries_gender[i] = sal2
}

# Initializing variables for predicting a person's salary based upon their education level
education_levels = c("Highschool", "Bachelor's Degree", "Master's Degree", "PhD", "Some College")
amazon_salaries_education = rep(0, length(education_levels))
google_salaries_education = rep(0, length(education_levels))

for(i in 1:length(education_levels)) {
  sal1 = exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = "White", Education = education_levels[i])))
  sal2 = exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = "White", Education = education_levels[i])))

  amazon_salaries_education[i] = sal1
  google_salaries_education[i] = sal2
}

#Predict salaries across each quartile
employee_q1 = data.frame(company = "Amazon", level = "L3", title = "Human Resources", yearsofexperience = 5, gender = "Female", Race = "Asian", Education = "Master's Degree") #61000
employee_q2 = data.frame(company = "Google", level = "L8", title = "Technical Program Manager", yearsofexperience = 22, gender = "Female", Race = "White", Education = "Bachelor's Degree") #694000
employee_q3 = data.frame(company = "Amazon", level = "L7", title = "Software Engineering Manager", yearsofexperience = 18, gender = "Other", Race = "Two Or More", Education = "Master's Degree") #800000
employee_q4 = data.frame(company = "Google", level = "L8", title = "Software Engineer", yearsofexperience = 23, gender = "Male", Race = "White", Education = "Bachelor's Degree") #1160000

pred_salary_q1 = exp(predict(aic_model_final, newdata = employee_q1))
pred_salary_q2 = exp(predict(aic_model_final, newdata = employee_q2))
pred_salary_q3 = exp(predict(aic_model_final, newdata = employee_q3))
pred_salary_q4 = exp(predict(aic_model_final, newdata = employee_q4))
actual_salary_q1 = 61000
actual_salary_q2 = 694000
actual_salary_q3 = 800000
actual_salary_q4 = 1160000

pe_q1 = get_percent_error(pred_salary_q1, actual_salary_q1)
pe_q2 = get_percent_error(pred_salary_q2, actual_salary_q2)
pe_q3 = get_percent_error(pred_salary_q3, actual_salary_q3)
pe_q4 = get_percent_error(pred_salary_q4, actual_salary_q4)

#Will be used later for the discussion on why google entry level is so high
#exp(predict(aic_model_final, data.frame(company = "Amazon", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
#exp(predict(aic_model_final, data.frame(company = "Google", level = "L1", title = "Software Engineer", yearsofexperience = 0, gender = "Male", Race = race[i], Education = "Bachelor's Degree"), interval = "prediction"))
```
***

### <u>Results</u>

#### Diagnostics

##### 1. Diagnostics Table
Should we mention loocv, shapiro, and bp when they don't look good? 
```{r}
row_names = c("LOOCV-RMSE", "Shapiro Test", "BP Test", "Average RMSE Train", "Average RMSE Test", "Percent Error")
column_names = c("Statistic", "Value")
diagnostics = c(loocv_rmse_final, shapiro_final, bp_final, mean(rmse_trn), mean(rmse_tst), percent_error)
df_results = data.frame(row_names, diagnostics)
kable(df_results, "simple", col.names = column_names)
```

##### 2. Goodness-Of-Fit

Comparison of Adjusted $R^2$ through model selection: 
```{r}
row_names = c("Initial Model", "AIC Model","Log Response Model", "Final Model")
column_names = c("Model", "Adjusted R")
adj_r = c(adj_initial, adj_aic, adj_log, adj_final)
df_results = data.frame(row_names, adj_r)
kable(df_results, "simple", col.names = column_names)
```

##### 3. Q-Q Plots

Comparison of the progression of Normal Q-Q plots through model selection:
```{r, fig.dim = c(12, 10)}
par(mfrow = c(1,3))

# Q-Q plot of initial model without log response transformation
qqnorm(resid(salaries_model_back_aic), main = "Normal Q-Q Plot Before Log Response", col = "darkgrey")
qqline(resid(salaries_model_back_aic), col = "dodgerblue", lwd = 2)

# Q-Q plot after log response transformation
qqnorm(resid(aic_model_log), main = "Normal Q-Q Plot After Log Response", col = "darkgrey")
qqline(resid(aic_model_log), col = "dodgerblue", lwd = 2)

# Q-Q plot after all transformations
qqnorm(resid(aic_model_final), main = "Normal Q-Q Plot After All Transformations", col = "darkgrey")
qqline(resid(aic_model_final), col = "dodgerblue", lwd = 2)
```

##### 4. Residuals vs. Fitted Plots

Comparison of the progression of Fitted Vs. Residuals plots through model selection:
```{r, fig.dim = c(12, 10)}
par(mfrow = c(1,3))

#Residuals vs Fitted plot of initial model without log response transformation
plot(fitted(salaries_model_back_aic), resid(salaries_model_back_aic), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Resids Before Log Response")
abline(h = 0, col = "darkorange", lwd = 2)

#Residuals vs Fitted plot after log response transformation
plot(fitted(aic_model_log), resid(aic_model_log), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Resids After Log Response")
abline(h = 0, col = "darkorange", lwd = 2)

#Residuals vs Fitted plot after all transformations
plot(fitted(aic_model_final), resid(aic_model_final), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted vs Resids After All Transformations")
abline(h = 0, col = "darkorange", lwd = 2)
```

##### 5. Percent Error - Fitted vs. Actual Salaries

```{r}
plot(pred_salary, actual_salary,
     col = "darkgrey",
     xlab = "Predicted Salaries Prices",
     ylab = "Actual Salaries",
     main = "Predicted vs. Actual Salaries",
     xlim = c(0, max_pe_salary),
     ylim = c(0, max_pe_salary)
     )
abline(0, 1, col = "dodgerblue")
```

##### 6. Practical Application of Model 

Table of Predicted Vs. Actual Salaries in Four Quartiles:
```{r}
row_names = c("First", "Second", "Third", "Fourth")
column_names = c("Quartile", "Predicted", "Actual", "Percent Error")
pred_salaries = c(pred_salary_q1, pred_salary_q2, pred_salary_q3, pred_salary_q4)
actual_salaries = c(actual_salary_q1, actual_salary_q2, actual_salary_q3, actual_salary_q4)
pe_salaries = c(pe_q1, pe_q2, pe_q3, pe_q4)
df_results = data.frame(row_names, pred_salaries, actual_salaries, pe_salaries)
kable(df_results, "simple", col.names = column_names)
```

Comparison Plots of Salaries Across Different Factors:
```{r, fig.dim = c(12, 10)}
# Define common y-axis limits
max_salary = max(c(amazon_salaries_race, google_salaries_race))*1.1

# Plot
par(mfrow = c(1,2))
barplot(amazon_salaries_race, names.arg = race, col=rainbow(length(amazon_salaries_race)), 
        main = "AMZN: L1 Salary Based on Race", ylab = "Total Compensation", ylim = c(0, max_salary))
barplot(google_salaries_race, names.arg = race, col=rainbow(length(google_salaries_race)), 
        main = "GOOG: L1 Salary Based on Race", ylab = "Total Compensation", ylim = c(0, max_salary))

# Plot
par(mfrow = c(1,2))
barplot(amazon_salaries_gender, names.arg = gender, col=c("blue", "red"), 
        main = "AMZN: L1 Salary Based on Gender", ylab = "Total Compensation", ylim = c(0, max_salary))
barplot(google_salaries_gender, names.arg = gender, col=c("blue", "red"), 
        main = "GOOG: L1 Salary Based on Gender", ylab = "Total Compensation", ylim = c(0, max_salary))

# Plot
par(mfrow = c(1,2))
barplot(amazon_salaries_education, names.arg = education_levels, col=rainbow(length(amazon_salaries_education)), 
        main = "AMZN: L1 Salary Based on Education Level", ylab = "Total Compensation", ylim = c(0, max_salary))
barplot(google_salaries_education, names.arg = education_levels, col=rainbow(length(google_salaries_education)), 
        main = "GOOG: L1 Salary Based on Education Level", ylab = "Total Compensation", ylim = c(0, max_salary))
```

***

### <u>Discussion</u>

#### Understanding the Final Model

Our final model, `aic_model_final`, includes interactions between company, years of experience, and title, along with other factors such as level, gender, race, and education. The model was carefully constructed through multiple steps including log transformation, interaction exploration, and removal of influential data points.

#### Key Findings

##### 1.Interactions

The interactions between company, years of experience, and title suggest that the relationship between these factors and total yearly compensation is not simply additive. This reflects the complexity of compensation structures in the real world, where various elements can synergistically affect the outcome.
  
DISCUSS improvement of ANOVA TESTS AND ADJUSTED R^2 HERE.

##### 2. Transformations and Subset Selection

Log transformation of the total yearly compensation helped to linearize the relationship with predictors. Additionally, the use of Cook's distance to exclude influential points contributed to model robustness. 
  
In our analysis, the Q-Q normal plots evolved across three models. In the first plot, the pattern formed by the plot points was nearly parallel to the diagonal line, with a wide y-axis range, indicating non-normality and potential outliers. As we moved to the second model, the y-axis range narrowed, and the pattern of the points started to resemble a more typical diagonal alignment, reflecting an improvement in normality. The third model continued this trend, though the most substantial shift occurred between the first and second models. These transitions signify our progression toward satisfying the normality assumption in the residual errors, a critical aspect in linear regression modeling.
 
Additionally, the first Residuals vs. Fitted Plot shows residuals clustering together, indicating potential non-linearity. In the second plot, the residuals begin to disperse, suggesting an improvement in linearity. The third plot further demonstrates this trend, with residuals more randomly scattered, adhering better to the assumptions of linear regression. The progression across these plots illustrates the model's refinement and increased ability to capture the underlying relationship in the data.

##### 3. Significance of Factors

The inclusion of categorical variables such as gender, race, and education may imply societal or industry-specific trends affecting salary. These factors should be interpreted with caution and in the context of broader research and understanding.

##### 4. Accuracy 

The final model we have selected demonstrated an accuracy rating of **`r 100 - percent_error`%**. This is indicative of the model's ability to fit the data, but it's worth noting that there may be room for further refinement and improvement. 

The Actual Vs. Predicted Salaries plot illustrates the correlation between our final model's salary predictions and the actual salaries. The points are largely concentrated around the diagonal line, where predicted values would equal actual values. This concentration signifies that the predictions are generally close to the actual figures, indicating the model's robustness and accuracy in predicting salaries. 

DISCUSS PREDICITIONS SECTION OF RESULTS HERE AS WELL. 

#### Utility of the Final Model

The final model, known as `aic_model_final`, represents an intricate understanding of how various factors like company, years of experience, title, level, gender, race, and education interact to influence total yearly compensation. This is not only a strategic tool for HR professionals but also a subject of great interest for data science students like us, and potentially a valuable resource for sociological studies.

The realization that factors such as gender, race, and education can significantly impact total yearly compensation even in tech companies brings additional depth to the model. It goes beyond mere corporate strategy, offering insights that can be applied in social science research to understand biases and inequalities in the workplace.

Individuals seeking jobs, organizations aiming to design more tailored and competitive compensation plans, and researchers examining societal trends can all benefit from this model. The nuanced understanding of how different variables interplay offers a unique lens into the underlying dynamics of the job market.

However, the model's utility is not without caveats. Its specific interactions and potential biases in data collection may limit its general application and scalability. The handling of sensitive areas such as gender and race requires thoughtful consideration, ensuring that insights align with ethical guidelines.

In conclusion, `aic_model_final` is a robust and multifaceted tool. Its applications are broad, ranging from individual and organizational decision-making to broader sociological analysis. It must be leveraged thoughtfully to realize its full potential and contribute to a more informed and equitable society.

#### Limitations and Areas for Improvement

There were various lessons learned while conducting this project. The first challenge the team encountered was during the initial data preparation phase. Because the dataset was a) crowd-sourced and b) scraped from a website, this led to many errors and inconsistencies which required vigorous data cleaning. The team used techniques including clustering, spell checks, removing missing fields, and cross validation in order to standardize the dataset. Ultimately, although we were able to produce a dataset fit for analysis, we were still limited by needing to rely on a user's "standard of truth" instead of an official or confirmed source. For example, a user could easily have input random attributes and we would have no way of knowing.

This leads to the next issue we faced, which was that the raw data was not evenly distributed across the various attributes. The data was heavily skewed towards mid-level entries, and we did not have data for nearly as many entry-level or executive-level positions. Additionally, there were far more entries for Amazon than Google employees. This presented a challenge when trying to build the model under LINE assumptions. 

In the future, there are several areas of improvement we'd explore:

- Gather more data from levels.fyi to ensure more even distribution and representation of salaries.
- Use an official source of employee data such as a database from the U.S. Department of Labor.
- Explore other models and techniques outside of linear regression to perhaps find a better model for prediction.

***

### <u>Appendix</u> 


```{r warning=FALSE}
#HERE FOR NOW BUT WILL BE CLEANED UP
salaries = read_csv("Levels-Fyi-Salary-Data-Cleaned-US.csv")

#Remove NA records
salaries = na.omit(salaries)

#Create new column 'State' which converts location to just the state abbreviation
salaries$state = str_sub(salaries$location,-2,-1)

#Changing some predictors to factors
salaries$company = as.factor(salaries$company)
salaries$level = as.factor(salaries$level)
salaries$title = as.factor(salaries$title)
salaries$location = as.factor(salaries$location)
salaries$state = as.factor(salaries$state)
salaries$gender = as.factor(salaries$gender)
salaries$Race = as.factor(salaries$Race)
salaries$Education = as.factor(salaries$Education)

#Variable Selection: Removed variables that contain redundant information or lack of information 
salaries = subset(salaries, select = c(company, level, title,
                                       totalyearlycompensation,
                                       yearsofexperience, yearsatcompany, tag,
                                       gender, Race, state, Education))
```


Linear Model that includes all predictors
```{r}
salaries_model = lm(totalyearlycompensation ~ ., data = salaries)
```

AIC/BIC Models
```{r}
#Didnt use p but n was used for model BIC models  
#p = length(coef(salaries_model))
n = length(resid(salaries_model))

#Backward AIC
salaries_model_back_aic = step(salaries_model,
                               direction = "backward", trace = 0)

#Backward BIC
salaries_model_back_bic = step(salaries_model, direction = "backward",
                               k = log(nrow(salaries)), trace = 0)

salaries_model_start = lm(totalyearlycompensation ~ 1, data = salaries)

#Forward AIC
salaries_model_forw_aic = step(salaries_model_start, 
                               scope = totalyearlycompensation ~ company + level +
                               title + yearsofexperience + yearsatcompany + tag +
                               gender + Race + Education + state,
                               direction = "forward", trace = 0)

#Forward BIC
salaries_model_forw_bic = step(salaries_model_start, 
                               scope = totalyearlycompensation ~ company + level +
                               title + yearsofexperience + yearsatcompany + tag +
                               gender + Race + Education + state,
                               direction = "forward", k = log(nrow(salaries)), trace = 0)

#Stepwise AIC
salaries_model_both_aic = step(salaries_model_start, 
                               scope = totalyearlycompensation ~ company + level +
                               title + yearsofexperience + yearsatcompany + tag +
                               gender + Race + Education + state,
                               direction = "both", trace = 0)

#Stepwise BIC
salaries_model_both_bic = step(salaries_model_start, 
                               scope = totalyearlycompensation ~ company + level +
                               title + yearsofexperience + yearsatcompany + tag +
                               gender + Race + Education + state,
                               direction = "both", k = log(nrow(salaries)), trace = 0)
```


-- Using AIC searching methods we derive the same model that use 9 of the 10 given predictors

  AIC Selected Predictors: **<u>`r all.vars(formula(salaries_model_both_aic)[-1])`</u>**
  
-- Using BIC searching methods we derive the same model that use 4 of the 10 given predictors

  AIC Selected Predictors: **<u>`r all.vars(formula(salaries_model_both_bic)[-1])`</u>**


Model 2 
```{r}
library(lmtest)
salaries_model_add = lm(log(totalyearlycompensation) ~ (yearsatcompany + company + title + state + level) ^ 2, data = salaries)
 
salaries_model_fix = lm(log(totalyearlycompensation) ~ (yearsatcompany + company + title + state + level) ^ 2, data = salaries, subset = cooks.distance(salaries_model_add) < 4 / length(cooks.distance(salaries_model_add)))

hist(resid(salaries_model_fix))
 
#salaries_model_int = lm(totalyearlycompensation ~ level * title * yearsofexperience * yearsatcompany, data = salaries)

#anova(salaries_model_add, salaries_model_int)
#summary(salaries_model_int)

#salaries_model_three_int = lm(totalyearlycompensation ~ company * level * yearsofexperience, data = salaries)

qqnorm(resid(salaries_model_fix))
qqline(resid(salaries_model_fix))
plot(fitted(salaries_model_fix), resid(salaries_model_fix))
abline(h=0)
shapiro.test(resid(salaries_model_fix))
bptest(salaries_model_fix)
#anova(salaries_model_add, salaries_model_two_int)

#anova(salaries_model_two_int, salaries_model_three_int)

```


Model Selection
```{r}
library(car)
library(lmtest)

get_loocv_rmse = function(model){
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}
#start_model = lm(log(totalyearlycompensation) ~ . ^ 2, data = salaries)
#aic_model = step(start_model, direction = "backward", trace = 0)
#Check for collinearity
car::vif(salaries_model_both_aic) #Nothing too bad, perhaps level is high

#Transform log response and add interactions to predictors to improve normality, linearity, constant variance, adjusted R-squared, and loocv-RMSE
aic_model_trans_2 = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + level + gender + Race + Education, data = salaries)

aic_model_trans = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + gender + Race + Education + level, data = salaries)

anova(aic_model_trans, aic_model_trans_2)

#Remove influential data from the model
aic_model_fix = lm(log(totalyearlycompensation) ~ (company + yearsofexperience + title) ^ 2 + gender + Race + Education + level, data = salaries, subset = cooks.distance(aic_model_trans) < 4 / length(cooks.distance(aic_model_trans)))

#Run diagnostics
summary(aic_model_fix)$adj 
get_loocv_rmse(aic_model_fix)
shapiro.test(resid(aic_model_fix))
bptest(aic_model_fix)

#Plot diagnostics
par(mfrow = c(1, 2))

# Residuals vs Fitted values plot
plot(fitted(aic_model_fix), resid(aic_model_fix), col = "grey", pch = 20,
     xlab = "Fitted", ylab = "Residuals", main = "Fitted versus Residuals")
abline(h = 0, col = "darkorange", lwd = 2)

# Q-Q plot
qqnorm(resid(aic_model_fix), main = "Normal Q-Q Plot", col = "darkgrey")
qqline(resid(aic_model_fix), col = "dodgerblue", lwd = 2)
```

Putting this in the appendix for now
```{r}
#Create new column 'State' which converts location to just the state abbreviation
#salaries$state = str_sub(salaries$location,-2,-1)
```

By: Nicholas O. Brown, Ellie Jung, Angela Mei

***

